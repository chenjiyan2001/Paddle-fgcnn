{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 23:33:13,950 P44563 INFO {\n",
      "    \"batch_norm\": \"False\",\n",
      "    \"batch_size\": \"1\",\n",
      "    \"channels\": \"[14, 16, 18, 20]\",\n",
      "    \"data_block_size\": \"-1\",\n",
      "    \"data_root\": \"../data/\",\n",
      "    \"dataset_id\": \"taobao_tiny\",\n",
      "    \"dnn_hidden_units\": \"[128, 64]\",\n",
      "    \"embedding_dim\": \"10\",\n",
      "    \"embedding_regularizer\": \"0\",\n",
      "    \"epochs\": \"3\",\n",
      "    \"every_x_epochs\": \"1\",\n",
      "    \"feature_cols\": \"[{'name': ['userid', 'adgroup_id', 'pid', 'cate_id', 'campaign_id', 'customer', 'brand', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level', 'pvalue_level', 'shopping_level', 'occupation'], 'active': True, 'dtype': 'str', 'type': 'categorical'}]\",\n",
      "    \"gpu\": \"-1\",\n",
      "    \"hidden_activations\": \"relu\",\n",
      "    \"kernel_heights\": \"[7, 7, 7, 7]\",\n",
      "    \"label_col\": \"{'name': 'clk', 'dtype': <class 'float'>}\",\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"loss\": \"binary_crossentropy\",\n",
      "    \"metrics\": \"['logloss', 'AUC']\",\n",
      "    \"min_categr_count\": \"1\",\n",
      "    \"model_id\": \"FGCNN_demo\",\n",
      "    \"model_root\": \"../checkpoints/\",\n",
      "    \"monitor\": \"AUC\",\n",
      "    \"monitor_mode\": \"max\",\n",
      "    \"net_dropout\": \"0\",\n",
      "    \"net_regularizer\": \"0\",\n",
      "    \"num_workers\": \"1\",\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"patience\": \"2\",\n",
      "    \"pickle_feature_encoder\": \"True\",\n",
      "    \"pooling_sizes\": \"[2, 2, 2, 2]\",\n",
      "    \"recombined_channels\": \"[3, 3, 3, 3]\",\n",
      "    \"save_best_only\": \"True\",\n",
      "    \"seed\": \"2019\",\n",
      "    \"shuffle\": \"True\",\n",
      "    \"task\": \"binary_classification\",\n",
      "    \"test_data\": \"../data/tiny_data/test_sample.csv\",\n",
      "    \"train_data\": \"../data/tiny_data/train_sample.csv\",\n",
      "    \"use_hdf5\": \"True\",\n",
      "    \"valid_data\": \"../data/tiny_data/valid_sample.csv\",\n",
      "    \"verbose\": \"1\",\n",
      "    \"version\": \"pytorch\"\n",
      "}\n",
      "2022-02-11 23:33:13,952 P44563 INFO Set up feature encoder...\n",
      "2022-02-11 23:33:13,953 P44563 INFO Reading file: ../data/tiny_data/train_sample.csv\n",
      "2022-02-11 23:33:13,962 P44563 INFO Reading file: ../data/tiny_data/valid_sample.csv\n",
      "2022-02-11 23:33:13,967 P44563 INFO Reading file: ../data/tiny_data/test_sample.csv\n",
      "2022-02-11 23:33:13,970 P44563 INFO Preprocess feature columns...\n",
      "2022-02-11 23:33:13,981 P44563 INFO Fit feature encoder...\n",
      "2022-02-11 23:33:13,983 P44563 INFO Processing column: {'name': 'userid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,985 P44563 INFO Processing column: {'name': 'adgroup_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,986 P44563 INFO Processing column: {'name': 'pid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,987 P44563 INFO Processing column: {'name': 'cate_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,989 P44563 INFO Processing column: {'name': 'campaign_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,991 P44563 INFO Processing column: {'name': 'customer', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,993 P44563 INFO Processing column: {'name': 'brand', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,994 P44563 INFO Processing column: {'name': 'cms_segid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,995 P44563 INFO Processing column: {'name': 'cms_group_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:13,997 P44563 INFO Processing column: {'name': 'final_gender_code', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:14,001 P44563 INFO Processing column: {'name': 'age_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:14,002 P44563 INFO Processing column: {'name': 'pvalue_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:14,004 P44563 INFO Processing column: {'name': 'shopping_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:14,006 P44563 INFO Processing column: {'name': 'occupation', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-02-11 23:33:14,007 P44563 INFO Set feature index...\n",
      "2022-02-11 23:33:14,007 P44563 INFO Pickle feature_encode: ../data/taobao_tiny/feature_encoder.pkl\n",
      "2022-02-11 23:33:14,008 P44563 INFO Save feature_map to json: ../data/taobao_tiny/feature_map.json\n",
      "2022-02-11 23:33:14,010 P44563 INFO Set feature encoder done.\n",
      "2022-02-11 23:33:14,012 P44563 INFO Transform feature columns...\n",
      "2022-02-11 23:33:14,015 P44563 INFO Saving data to h5: ../data/taobao_tiny/train.h5\n",
      "2022-02-11 23:33:14,109 P44563 INFO Preprocess feature columns...\n",
      "2022-02-11 23:33:14,115 P44563 INFO Transform feature columns...\n",
      "2022-02-11 23:33:14,117 P44563 INFO Saving data to h5: ../data/taobao_tiny/valid.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chen/code/PaperReproduction/fgcnn/FuxiCTR/demo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-11 23:33:14,198 P44563 INFO Preprocess feature columns...\n",
      "2022-02-11 23:33:14,206 P44563 INFO Transform feature columns...\n",
      "2022-02-11 23:33:14,210 P44563 INFO Saving data to h5: ../data/taobao_tiny/test.h5\n",
      "2022-02-11 23:33:14,284 P44563 INFO Transform csv data to h5 done.\n",
      "2022-02-11 23:33:14,285 P44563 INFO Loading data...\n",
      "2022-02-11 23:33:14,287 P44563 INFO Loading data from h5: ../data/taobao_tiny/train.h5\n",
      "2022-02-11 23:33:14,289 P44563 INFO Loading data from h5: ../data/taobao_tiny/valid.h5\n",
      "2022-02-11 23:33:14,291 P44563 INFO Train samples: total/100, pos/4, neg/96, ratio/4.00%, blocks/1\n",
      "2022-02-11 23:33:14,291 P44563 INFO Validation samples: total/100, pos/4, neg/96, ratio/4.00%, blocks/1\n",
      "2022-02-11 23:33:14,292 P44563 INFO Loading train data done.\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/PaperReproduction/fgcnn/FuxiCTR/demo\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from fuxictr import datasets\n",
    "from fuxictr.datasets.taobao import FeatureEncoder\n",
    "from fuxictr.features import FeatureMap\n",
    "from fuxictr.utils import load_config, set_logger, print_to_json\n",
    "from fuxictr.pytorch.models import FGCNN\n",
    "from fuxictr.pytorch.torch_utils import seed_everything\n",
    "import torch\n",
    "\n",
    "feature_cols = [{'name': [\"userid\",\"adgroup_id\",\"pid\",\"cate_id\",\"campaign_id\",\"customer\",\"brand\",\"cms_segid\",\n",
    "                            \"cms_group_id\",\"final_gender_code\",\"age_level\",\"pvalue_level\",\"shopping_level\",\"occupation\"],\n",
    "                    'active': True, 'dtype': 'str', 'type': 'categorical'}]\n",
    "label_col = {'name': 'clk', 'dtype': float}\n",
    "\n",
    "params = {'model_id': 'FGCNN_demo',\n",
    "            'dataset_id': 'taobao_tiny',\n",
    "            'train_data': '../data/tiny_data/train_sample.csv',\n",
    "            'valid_data': '../data/tiny_data/valid_sample.csv',\n",
    "            'test_data': '../data/tiny_data/test_sample.csv',\n",
    "            'model_root': '../checkpoints/',\n",
    "            'data_root': '../data/',\n",
    "            'feature_cols': feature_cols,\n",
    "            'label_col': label_col,\n",
    "            'embedding_regularizer': 0,\n",
    "            'net_regularizer': 0,\n",
    "            'dnn_hidden_units': [128, 64],\n",
    "            \"channels\": [14, 16, 18, 20],\n",
    "            \"kernel_heights\": [7, 7, 7, 7],\n",
    "            'hidden_activations': \"relu\",\n",
    "            'learning_rate': 1e-3,\n",
    "            'net_dropout': 0,\n",
    "            'batch_norm': False,\n",
    "            'optimizer': 'adam',\n",
    "            'task': 'binary_classification',\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'metrics': ['logloss', 'AUC'],\n",
    "            'min_categr_count': 1,\n",
    "            'embedding_dim': 10,\n",
    "            \"pooling_sizes\": [2, 2, 2, 2],\n",
    "            \"recombined_channels\": [3, 3, 3, 3],\n",
    "            'batch_size': 1,\n",
    "            'epochs': 3,\n",
    "            'shuffle': True,\n",
    "            'seed': 2019,\n",
    "            'monitor': 'AUC',\n",
    "            'monitor_mode': 'max',\n",
    "            'use_hdf5': True,\n",
    "            'pickle_feature_encoder': True,\n",
    "            'save_best_only': True,\n",
    "            'every_x_epochs': 1,\n",
    "            'patience': 2,\n",
    "            'num_workers': 1,\n",
    "            'data_block_size': -1,\n",
    "            'verbose': 1,\n",
    "            'version': 'pytorch',\n",
    "            'gpu': -1}\n",
    "\n",
    "set_logger(params)\n",
    "logging.info(print_to_json(params))\n",
    "seed_everything(seed=params['seed'])\n",
    "\n",
    "# Set feature_encoder that defines how to preprocess data\n",
    "feature_encoder = FeatureEncoder(feature_cols, \n",
    "                                    label_col, \n",
    "                                    dataset_id=params['dataset_id'], \n",
    "                                    data_root=params[\"data_root\"])\n",
    "\n",
    "# Build dataset from csv to h5\n",
    "datasets.build_dataset(feature_encoder, \n",
    "                        train_data=params[\"train_data\"], \n",
    "                        valid_data=params[\"valid_data\"], \n",
    "                        test_data=params[\"test_data\"])\n",
    "\n",
    "# Get feature_map that defines feature specs\n",
    "feature_map = feature_encoder.feature_map\n",
    "\n",
    "# Get train and validation data generator from h5\n",
    "data_dir = os.path.join(params['data_root'], params['dataset_id'])\n",
    "train_gen, valid_gen = datasets.h5_generator(feature_map, \n",
    "                                                stage='train', \n",
    "                                                train_data=os.path.join(data_dir, 'train.h5'),\n",
    "                                                valid_data=os.path.join(data_dir, 'valid.h5'),\n",
    "                                                batch_size=params['batch_size'],\n",
    "                                                shuffle=params['shuffle'])\n",
    "\n",
    "# Model initialization and fitting                                                  \n",
    "torch_model = FGCNN(feature_map, **params)\n",
    "# model.count_parameters() # print number of parameters used in model\n",
    "# model.fit_generator(train_gen, \n",
    "#                     validation_data=valid_gen, \n",
    "#                     epochs=params['epochs'],\n",
    "#                     verbose=params['verbose'])\n",
    "# model.load_weights(model.checkpoint) # reload the best checkpoint\n",
    "\n",
    "# logging.info('***** validation results *****')\n",
    "# model.evaluate_generator(valid_gen)\n",
    "\n",
    "# logging.info('***** validation results *****')\n",
    "# test_gen = datasets.h5_generator(feature_map, \n",
    "#                                     stage='test',\n",
    "#                                     test_data=os.path.join(data_dir, 'test.h5'),\n",
    "#                                     batch_size=params['batch_size'],\n",
    "#                                     shuffle=False)\n",
    "# model.evaluate_generator(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FuxiCTR-FGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chen/code/PaperReproduction/fgcnn/FuxiCTR\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/PaperReproduction/fgcnn/FuxiCTR\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from fuxictr.pytorch.models.base_model import BaseModel\n",
    "from fuxictr.pytorch.layers import EmbeddingLayer#, InnerProductLayer\n",
    "from fuxictr.pytorch.torch_utils import set_activation\n",
    "\n",
    "class fuxi_FGCNN(BaseModel):\n",
    "    def __init__(self, \n",
    "                 feature_map, \n",
    "                 model_id=\"FGCNN\", \n",
    "                 gpu=-1, \n",
    "                 task=\"binary_classification\", \n",
    "                 learning_rate=1e-3, \n",
    "                 embedding_dim=10, \n",
    "                 share_embedding=False,\n",
    "                 channels=[14, 16, 18, 20],\n",
    "                 kernel_heights=[7, 7, 7, 7],\n",
    "                 pooling_sizes=[2, 2, 2, 2],\n",
    "                 recombined_channels=[2, 2, 2, 2],\n",
    "                 conv_activation=\"Tanh\",\n",
    "                 conv_batch_norm=True,\n",
    "                 dnn_hidden_units=[128, 64],\n",
    "                 dnn_activations=\"ReLU\",\n",
    "                 dnn_batch_norm=False, \n",
    "                 embedding_regularizer=None, \n",
    "                 net_regularizer=None,\n",
    "                 net_dropout=0,\n",
    "                 **kwargs):\n",
    "        super(fuxi_FGCNN, self).__init__(feature_map, \n",
    "                                    model_id=model_id, \n",
    "                                    gpu=gpu, \n",
    "                                    embedding_regularizer=embedding_regularizer, \n",
    "                                    net_regularizer=net_regularizer,\n",
    "                                    **kwargs)\n",
    "        self.share_embedding = share_embedding\n",
    "        self.embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        if not self.share_embedding:\n",
    "            self.fg_embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        num_fields = feature_map.num_fields\n",
    "        channels, kernel_heights, pooling_sizes, recombined_channels \\\n",
    "            = self.validate_input(channels, \n",
    "                                  kernel_heights, \n",
    "                                  pooling_sizes, \n",
    "                                  recombined_channels)\n",
    "        self.fgcnn_layer = FGCNN_Layer(num_fields, \n",
    "                                       embedding_dim,\n",
    "                                       channels=channels, \n",
    "                                       kernel_heights=kernel_heights, \n",
    "                                       pooling_sizes=pooling_sizes,\n",
    "                                       recombined_channels=recombined_channels,\n",
    "                                       activation=conv_activation,\n",
    "                                       batch_norm=conv_batch_norm)\n",
    "        input_dim, total_features = self.compute_input_dim(embedding_dim, \n",
    "                                                           num_fields, \n",
    "                                                           channels, \n",
    "                                                           pooling_sizes, \n",
    "                                                           recombined_channels)\n",
    "        self.inner_product_layer = InnerProductLayer(total_features)#, output=\"inner_product\")\n",
    "        self.dnn = MLP_Layer(input_dim=input_dim,\n",
    "                             output_dim=1, \n",
    "                             hidden_units=dnn_hidden_units,\n",
    "                             hidden_activations=dnn_activations,\n",
    "                             final_activation=nn.Sigmoid(),\n",
    "                             dropout_rates=net_dropout,\n",
    "                             batch_norm=dnn_batch_norm)\n",
    "        # self.compile(kwargs[\"optimizer\"], loss=kwargs[\"loss\"], lr=learning_rate)\n",
    "        # self.apply(self.init_weights)\n",
    "\n",
    "    def compute_input_dim(self, \n",
    "                          embedding_dim, \n",
    "                          num_fields, \n",
    "                          channels, \n",
    "                          pooling_sizes, \n",
    "                          recombined_channels):\n",
    "        total_features = num_fields\n",
    "        input_height = num_fields\n",
    "        for i in range(len(channels)):\n",
    "            input_height = int(np.ceil(input_height / pooling_sizes[i]))\n",
    "            total_features += input_height * recombined_channels[i]\n",
    "        input_dim = int(total_features * (total_features - 1) / 2) \\\n",
    "                  + total_features * embedding_dim\n",
    "        return input_dim, total_features\n",
    "\n",
    "    def validate_input(self, \n",
    "                       channels, \n",
    "                       kernel_heights, \n",
    "                       pooling_sizes, \n",
    "                       recombined_channels):\n",
    "        if not isinstance(kernel_heights, list):\n",
    "            kernel_heights = [kernel_heights] * len(channels)\n",
    "        if not isinstance(pooling_sizes, list):\n",
    "            pooling_sizes = [pooling_sizes] * len(channels)\n",
    "        if not isinstance(recombined_channels, list):\n",
    "            recombined_channels = [recombined_channels] * len(channels)\n",
    "        if not (len(channels) == len(kernel_heights) == len(pooling_sizes) == len(recombined_channels)):\n",
    "            raise ValueError(\"channels, kernel_heights, pooling_sizes, and recombined_channels \\\n",
    "                              should have the same length.\")\n",
    "        return channels, kernel_heights, pooling_sizes, recombined_channels\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Inputs: [X, y]\n",
    "        \"\"\"\n",
    "        X, y = self.inputs_to_device(inputs)\n",
    "        feature_emb = self.embedding_layer(X)\n",
    "        if not self.share_embedding:\n",
    "            feature_emb2 = self.fg_embedding_layer(X)\n",
    "        else:\n",
    "            feature_emb2 = feature_emb\n",
    "        conv_in = torch.unsqueeze(feature_emb2, 1) # shape (bs, 1, field, emb)\n",
    "        # print('fg_input:', conv_in.shape)\n",
    "        new_feature_emb = self.fgcnn_layer(conv_in)\n",
    "        # return new_feature_emb\n",
    "        # print('new_features:', new_feature_emb.shape)\n",
    "        combined_feature_emb = torch.cat([feature_emb, new_feature_emb], dim=1)\n",
    "        # return combined_feature_emb\n",
    "        # print('combine_input:', combined_feature_emb.shape)\n",
    "        inner_product_vec = self.inner_product_layer(combined_feature_emb)\n",
    "        # return inner_product_vec\n",
    "        # print('inner_product:', inner_product_vec.shape)\n",
    "        dense_input = torch.cat([combined_feature_emb.flatten(start_dim=1), inner_product_vec], dim=1)\n",
    "        # dense_input = combined_feature_emb.flatten(start_dim=1)\n",
    "        # print('dnn_input:', dense_input.shape)\n",
    "        # return dense_input\n",
    "        y_pred = self.dnn(dense_input)\n",
    "        return y_pred\n",
    "        return_dict = {\"y_true\": y, \"y_pred\": y_pred}\n",
    "        return return_dict\n",
    "\n",
    "\n",
    "class FGCNN_Layer(nn.Module):\n",
    "    \"\"\"\n",
    "    Input X: tensor of shape (batch_size, 1, num_fields, embedding_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_fields, \n",
    "                 embedding_dim,\n",
    "                 channels=[3], \n",
    "                 kernel_heights=[3], \n",
    "                 pooling_sizes=[2],\n",
    "                 recombined_channels=[2],\n",
    "                 activation=\"Tanh\",\n",
    "                 batch_norm=True):\n",
    "        super(FGCNN_Layer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        conv_list = []\n",
    "        recombine_list = []\n",
    "        self.channels = [1] + channels # input channel = 1\n",
    "        input_height = num_fields\n",
    "        for i in range(1, len(self.channels)):\n",
    "            in_channel = self.channels[i - 1]\n",
    "            out_channel = self.channels[i]\n",
    "            kernel_height = kernel_heights[i - 1]\n",
    "            pooling_size = pooling_sizes[i - 1]\n",
    "            recombined_channel = recombined_channels[i - 1]\n",
    "            # print('in: %d, out: %d, kernel: %d, pool: %d, recombine: %d' % \\\n",
    "            #     (in_channel, out_channel, kernel_height, pooling_size, recombined_channel))\n",
    "            conv_list.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, \n",
    "                        kernel_size=(kernel_height, 1), \n",
    "                        padding=(int((kernel_height - 1) / 2), 0)),\n",
    "                nn.BatchNorm2d(out_channel),\n",
    "                nn.Tanh(),\n",
    "                nn.MaxPool2d((pooling_size, 1), stride=(pooling_size, 1), padding=(input_height % pooling_size, 0))\n",
    "            ))\n",
    "            input_height = int(np.ceil(input_height / pooling_size))\n",
    "            input_dim =  input_height * embedding_dim * out_channel\n",
    "            output_dim = input_height * embedding_dim * recombined_channel\n",
    "            # print('in: %d, out:%d' % (input_dim, output_dim))\n",
    "            recombine_layer = nn.Sequential(nn.Linear(input_dim, output_dim),\n",
    "                                            nn.Tanh())\n",
    "            recombine_list.append(recombine_layer)\n",
    "        self.conv_layers = nn.ModuleList(conv_list)\n",
    "        self.recombine_layers = nn.ModuleList(recombine_list)\n",
    "\n",
    "    def forward(self, X):\n",
    "        conv_out = X\n",
    "        new_feature_list = []\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            conv_out = self.conv_layers[i](conv_out)\n",
    "            flatten_out = torch.flatten(conv_out, start_dim=1)\n",
    "            # return flatten_out\n",
    "            # print(i)\n",
    "            # print('\\tflatten_out:', flatten_out.shape)\n",
    "            recombine_out = self.recombine_layers[i](flatten_out)\n",
    "            # return recombine_out\n",
    "            # print('\\trecombine_out:', recombine_out.shape)\n",
    "            new_feature_list.append(recombine_out.reshape(X.size(0), -1, self.embedding_dim))\n",
    "        # return new_feature_list\n",
    "        new_feature_emb = torch.cat(new_feature_list, dim=1)\n",
    "        return new_feature_emb\n",
    "\n",
    "class MLP_Layer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 output_dim=None, \n",
    "                 hidden_units=[], \n",
    "                 hidden_activations=\"ReLU\",\n",
    "                 final_activation=None, \n",
    "                 dropout_rates=[], \n",
    "                 batch_norm=False, \n",
    "                 use_bias=True):\n",
    "        super(MLP_Layer, self).__init__()\n",
    "        dense_layers = []\n",
    "        if not isinstance(dropout_rates, list):\n",
    "            dropout_rates = [dropout_rates] * len(hidden_units)\n",
    "        if not isinstance(hidden_activations, list):\n",
    "            hidden_activations = [hidden_activations] * len(hidden_units)\n",
    "        hidden_activations = [set_activation(x) for x in hidden_activations]\n",
    "        hidden_units = [input_dim] + hidden_units\n",
    "        for idx in range(len(hidden_units) - 1):\n",
    "            dense_layers.append(nn.Linear(hidden_units[idx], hidden_units[idx + 1], bias=use_bias))\n",
    "            if batch_norm:\n",
    "                dense_layers.append(nn.BatchNorm1d(hidden_units[idx + 1]))\n",
    "            if hidden_activations[idx]:\n",
    "                dense_layers.append(hidden_activations[idx])\n",
    "            if dropout_rates[idx] > 0:\n",
    "                dense_layers.append(nn.Dropout(p=dropout_rates[idx]))\n",
    "        if output_dim is not None:\n",
    "            dense_layers.append(nn.Linear(hidden_units[-1], output_dim, bias=use_bias))\n",
    "        if final_activation is not None:\n",
    "            dense_layers.append(set_activation(final_activation))\n",
    "        self.dnn = nn.Sequential(*dense_layers) # * used to unpack list\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.dnn(inputs)\n",
    "\n",
    "# class InnerProductLayer(nn.Module):\n",
    "#     def __init__(self, num_fields=None):\n",
    "#         super(InnerProductLayer, self).__init__()\n",
    "#         self.interaction_units = int(num_fields * (num_fields - 1) / 2)\n",
    "#         self.upper_triange_mask = torch.triu(torch.ones(num_fields, num_fields), 1).type(torch.BoolTensor)\n",
    "\n",
    "#     def forward(self, feature_emb):\n",
    "#         inner_product_matrix = torch.bmm(feature_emb, feature_emb.transpose(1, 2))\n",
    "#         flat_upper_triange = torch.masked_select(inner_product_matrix, self.upper_triange_mask)\n",
    "#         return flat_upper_triange.view(-1, self.interaction_units)\n",
    "\n",
    "# deepctr\n",
    "class InnerProductLayer(nn.Module):\n",
    "    def __init__(self, num_fields):\n",
    "        super(InnerProductLayer, self).__init__()\n",
    "        self.num_fields = num_fields\n",
    "    \n",
    "    def forward(self, feature_emb):\n",
    "        # print(feature_emb.shape)\n",
    "        embed_list = torch.split(\n",
    "            tensor=feature_emb, \n",
    "            split_size_or_sections=feature_emb.shape[0], \n",
    "            dim=1)\n",
    "        row = []\n",
    "        col = []\n",
    "\n",
    "        for i in range(self.num_fields - 1):\n",
    "            for j in range(i + 1, self.num_fields):\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "        # print(embed_list[0].shape)\n",
    "        p = torch.cat([embed_list[idx] for idx in row], dim=1)  # batch num_pairs k\n",
    "        q = torch.cat([embed_list[idx] for idx in col], dim=1)\n",
    "        inner_product = p * q\n",
    "        inner_product = torch.sum(inner_product, dim=2, keepdim=True)\n",
    "        # print(inner_product.shape)\n",
    "        return inner_product.reshape(inner_product.shape[:2])\n",
    "\n",
    "torch_model = fuxi_FGCNN(feature_map, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paddle-FGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "from paddle.nn import functional as F\n",
    "\n",
    "\n",
    "class paddle_FGCNN(nn.Layer):\n",
    "    def __init__(self, sparse_num_field, sparse_feature_size,\n",
    "                 sparse_feature_name, sparse_feature_dim, conv_kernel_width,\n",
    "                 conv_filters, new_maps, pooling_width,\n",
    "                 dnn_hidden_units, dnn_dropout):\n",
    "        '''\n",
    "        Parameters\n",
    "            sparse_num_field - \n",
    "            sparse_feature_size - \n",
    "            sparse_feature_name - \n",
    "            sparse_feature_dim - \n",
    "            conv_kernel_width - \n",
    "            conv_filters - \n",
    "            new_maps - \n",
    "            pooling_width - \n",
    "            dnn_hidden_units - \n",
    "            dnn_dropout - \n",
    "        '''\n",
    "        super(paddle_FGCNN, self).__init__()\n",
    "        self.sparse_num_field = sparse_num_field\n",
    "        self.sparse_feature_size = sparse_feature_size\n",
    "        self.sparse_feature_name = sparse_feature_name\n",
    "        self.sparse_feature_dim = sparse_feature_dim\n",
    "        self.conv_filters = conv_filters\n",
    "        self.conv_kernel_width = conv_kernel_width\n",
    "        self.new_maps = new_maps\n",
    "        self.pooling_width = pooling_width\n",
    " \n",
    "        \n",
    "        self.fg_embedding = nn.LayerList([\n",
    "            EmbeddingLayer(\n",
    "                num_embeddings=self.sparse_feature_size[i],\n",
    "                embedding_dim=self.sparse_feature_dim,\n",
    "                feature_name=self.sparse_feature_name[i] + '_fg_emd'\n",
    "            ) for i in range(self.sparse_num_field)])\n",
    "\n",
    "        self.embedding = nn.LayerList([\n",
    "            EmbeddingLayer(\n",
    "                num_embeddings=self.sparse_feature_size[i],\n",
    "                embedding_dim=self.sparse_feature_dim,\n",
    "                feature_name=self.sparse_feature_name[i] + '_emd'\n",
    "            ) for i in range(self.sparse_num_field)])\n",
    "\n",
    "        self.fgcnn = FGCNNLayer(self.sparse_num_field, self.sparse_feature_dim,\n",
    "                                self.conv_filters, self.conv_kernel_width, \n",
    "                                self.new_maps, self.pooling_width)\n",
    "        input_dim, total_features = self.compute_input_dim(\n",
    "            self.sparse_feature_dim,\n",
    "            self.sparse_num_field,\n",
    "            self.conv_filters,\n",
    "            self.pooling_width, \n",
    "            self.new_maps)\n",
    "        self.inner_product_layer = InnerProductLayer(total_features)\n",
    "        self.dnn = DNNLayer(input_dim, dnn_hidden_units, dnn_dropout)\n",
    "\n",
    "    def compute_input_dim(self, embedding_dim, num_fields, channels, \n",
    "                          pooling_sizes, recombined_channels):\n",
    "        total_features = num_fields\n",
    "        input_height = num_fields\n",
    "        for i in range(len(channels)):\n",
    "            input_height = int(np.ceil(input_height / pooling_sizes[i]))\n",
    "            total_features += input_height * recombined_channels[i]\n",
    "        input_dim = int(total_features * (total_features - 1) / 2) \\\n",
    "                  + total_features * embedding_dim\n",
    "        return input_dim, total_features\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = paddle.to_tensor(inputs).reshape((-1, self.sparse_num_field))\n",
    "        fg_input_list = []\n",
    "        origin_input_list = []\n",
    "        for i in range(self.sparse_num_field):\n",
    "            fg_input_list.append(\n",
    "                self.fg_embedding[i](inputs[:, i].astype('int64'))\n",
    "                .reshape((-1, 1, self.sparse_feature_dim)))\n",
    "            origin_input_list.append(\n",
    "                self.embedding[i](inputs[:, i].astype('int64'))\n",
    "                .reshape((-1, 1, self.sparse_feature_dim)))\n",
    "        fg_input = paddle.concat(fg_input_list, axis=1)\n",
    "        origin_input = paddle.concat(origin_input_list, axis=1)\n",
    "        new_features = self.fgcnn(fg_input)\n",
    "        # return new_features\n",
    "        # print('fg_input:', fg_input.shape)\n",
    "        # print('new_features:', new_features.shape)\n",
    "        combined_input = paddle.concat([origin_input, new_features], axis=1)\n",
    "        # return combined_input\n",
    "        # print('combine_input:', combined_input.shape)\n",
    "        # # inner product\n",
    "        # embed_list = paddle.split(\n",
    "        #     x=combined_input, \n",
    "        #     num_or_sections=combined_input.shape[1], \n",
    "        #     axis=1)\n",
    "        # row = []\n",
    "        # col = []\n",
    "        # num_inputs = len(embed_list)\n",
    "        # for i in range(num_inputs - 1):\n",
    "        #     for j in range(i + 1, num_inputs):\n",
    "        #         row.append(i)\n",
    "        #         col.append(j)\n",
    "        # p = paddle.concat([embed_list[idx] for idx in row], axis=1)  # batch num_pairs k\n",
    "        # q = paddle.concat([embed_list[idx] for idx in col], axis=1)\n",
    "\n",
    "        # # inner_product = paddle.sum(p * q, axis=2, keepdim=True)\n",
    "        # inner_product = paddle.flatten(inner_product, start_axis=1)\n",
    "        # # return inner_product\n",
    "        linear_signal = paddle.flatten(combined_input, start_axis=1)\n",
    "        inner_product_vec = self.inner_product_layer(combined_input)\n",
    "        # print('linear_signal:', linear_signal.shape)\n",
    "        # print('inner_prodcut', inner_product.shape)\n",
    "        dnn_input = paddle.concat([linear_signal, inner_product_vec], axis=1)\n",
    "        # dnn_input = linear_signal\n",
    "        # return dnn_input\n",
    "        # print('dnn_input:', dnn_input.shape)\n",
    "        y_pred = self.dnn(dnn_input)\n",
    "        return y_pred\n",
    "\n",
    "class EmbeddingLayer(nn.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, feature_name):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "            name=feature_name,\n",
    "            sparse=True\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.embedding(inputs)\n",
    "    \n",
    "class FGCNNLayer(nn.Layer):\n",
    "    def __init__(self, sparse_num_field, embedding_size, filters, kernel_width, new_maps, pooling_width):\n",
    "        super(FGCNNLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        conv_list = []\n",
    "        recombine_list = []\n",
    "        self.filters = [1] + filters # input channel = 1\n",
    "        input_height = sparse_num_field\n",
    "        for i in range(1, len(self.filters)):\n",
    "            in_channel = self.filters[i - 1]\n",
    "            out_channel = self.filters[i]\n",
    "            kernel_height = kernel_width[i - 1]\n",
    "            pooling_size = pooling_width[i - 1]\n",
    "            recombined_channel = new_maps[i - 1]\n",
    "            conv_layer = nn.Sequential(\n",
    "                nn.Conv2D(\n",
    "                    in_channels=in_channel, \n",
    "                    out_channels=out_channel, \n",
    "                    kernel_size=(kernel_height, 1), \n",
    "                    padding=(int((kernel_height - 1) / 2), 0)),\n",
    "                nn.BatchNorm2D(out_channel),\n",
    "                nn.Tanh(),\n",
    "                nn.MaxPool2D(\n",
    "                    kernel_size=(pooling_size, 1), \n",
    "                    stride=(pooling_size, 1),\n",
    "                    padding=(input_height % pooling_size, 0)))\n",
    "            # )\n",
    "            conv_list.append(conv_layer)\n",
    "\n",
    "            input_height = int(np.ceil(input_height / pooling_size))\n",
    "            input_dim =  input_height * embedding_size * out_channel\n",
    "            output_dim = input_height * embedding_size * recombined_channel\n",
    "            # print('in: %d, out:%d' % (input_dim, output_dim))\n",
    "            recombine_layer = nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    in_features=input_dim, \n",
    "                    out_features=output_dim), \n",
    "                nn.Tanh())\n",
    "            recombine_list.append(recombine_layer)\n",
    "\n",
    "        self.conv_layers = nn.LayerList(conv_list)\n",
    "        self.recombine_layers = nn.LayerList(recombine_list)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        conv_out = inputs.unsqueeze(1)\n",
    "        new_feature_list = []\n",
    "        for i in range(len(self.filters) - 1):\n",
    "            conv_out = self.conv_layers[i](conv_out)\n",
    "            flatten_out = paddle.flatten(conv_out, start_axis=1)\n",
    "            # return flatten_out\n",
    "            recombine_out = self.recombine_layers[i](flatten_out)\n",
    "            # print(flatten_out.shape)\n",
    "            # return recombine_out\n",
    "            recombine_out = recombine_out.reshape((inputs.shape[0], -1, self.embedding_size))\n",
    "            new_feature_list.append(recombine_out)\n",
    "        # return new_feature_list\n",
    "        new_features = paddle.concat(new_feature_list, axis=1)\n",
    "        return new_features\n",
    "\n",
    "class InnerProductLayer(nn.Layer):\n",
    "    def __init__(self, num_fields):\n",
    "        super(InnerProductLayer, self).__init__()\n",
    "        # fuxictr\n",
    "        self.interaction_units = int(num_fields * (num_fields - 1) / 2)\n",
    "        self.upper_triange_mask = paddle.triu(paddle.ones((num_fields, num_fields)), 1).astype('bool')\n",
    "    \n",
    "    def forward(self, feature_emb):\n",
    "        # deepctr\n",
    "        # print(feature_emb.shape)\n",
    "        embed_list = paddle.split(\n",
    "            x=feature_emb, \n",
    "            num_or_sections=feature_emb.shape[1], \n",
    "            axis=1)\n",
    "        row = []\n",
    "        col = []\n",
    "        num_inputs = len(embed_list)\n",
    "        # print(feature_emb.shape, num_inputs)\n",
    "        for i in range(num_inputs - 1):\n",
    "            for j in range(i + 1, num_inputs):\n",
    "                row.append(i)\n",
    "                col.append(j)\n",
    "        # print(embed_list[0].shape)\n",
    "        p = paddle.concat([embed_list[idx] for idx in row], axis=1)  # batch num_pairs k\n",
    "        q = paddle.concat([embed_list[idx] for idx in col], axis=1)\n",
    "\n",
    "        inner_product = paddle.sum(p * q, axis=2, keepdim=True)\n",
    "        inner_product = paddle.flatten(inner_product, start_axis=1)\n",
    "        # print(inner_product.shape)\n",
    "        return inner_product\n",
    "        # # fuxictr\n",
    "        # inner_product_matrix = paddle.bmm(feature_emb, feature_emb.transpose((0, 2, 1)))\n",
    "        # mask = map(lambda mat: paddle.masked_select(mat, self.upper_triange_mask), inner_product_matrix)\n",
    "        # flat_upper_triange = paddle.to_tensor(list(mask))\n",
    "        # return flat_upper_triange.reshape((-1, self.interaction_units))\n",
    "\n",
    "class DNNLayer(nn.Layer):\n",
    "    def __init__(self, inputs_dim, hidden_units, dropout_rate):\n",
    "        super(DNNLayer, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        hidden_units = [inputs_dim] + list(hidden_units)\n",
    "        layers = []\n",
    "        for i in range(len(hidden_units) - 1):\n",
    "            layers.append(nn.Linear(\n",
    "                in_features=hidden_units[i], \n",
    "                out_features=hidden_units[i + 1],\n",
    "                name='dnn_%d' % i))\n",
    "            layers.append(nn.ReLU())\n",
    "            if self.dropout_rate > 0:\n",
    "                layers.append(self.dropout)\n",
    "        layers.append(nn.Linear(\n",
    "            in_features=hidden_units[-1],\n",
    "            out_features=1,\n",
    "            name='dnn_%d' % (i+1)))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.dnn = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        return self.dnn(inputs)\n",
    "\n",
    "# hyperparameters\n",
    "sparse_num_field = 14\n",
    "sparse_feature_size = [25, 95, 3, 48, 98, 97, 66, 10, 10, 3, 6, 3, 4, 3]\n",
    "sparse_feature_name = ['userid', 'adgroup_id', 'pid', 'cate_id', 'campaign_id', 'customer', 'brand', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level', 'pvalue_level', 'shopping_level', 'occupation']\n",
    "sparse_feature_dim = 10\n",
    "conv_kernel_width =  [7, 7, 7, 7]\n",
    "conv_filters =  [14, 16, 18, 20]\n",
    "new_maps =  [3, 3, 3, 3]\n",
    "pooling_width =  [2, 2, 2, 2]\n",
    "dnn_hidden_units =  [128, 64]\n",
    "dnn_dropout =  0.0\n",
    "paddle_model = paddle_FGCNN(sparse_num_field, sparse_feature_size,\n",
    "                 sparse_feature_name, sparse_feature_dim, conv_kernel_width,\n",
    "                 conv_filters, new_maps, pooling_width,\n",
    "                 dnn_hidden_units, dnn_dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import paddle\n",
    "# from paddle_net import FGCNN as paddle_FGCNN\n",
    "from reprod_log import ReprodLogger, ReprodDiffHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chen/code/PaperReproduction/fgcnn/fuxi_pipline\n"
     ]
    }
   ],
   "source": [
    "# path\n",
    "%cd ~/code/PaperReproduction/fgcnn/fuxi_pipline\n",
    "# data\n",
    "pipline_data = pickle.load(open('data/sample.pkl', 'rb'))\n",
    "# torch\n",
    "torch_para = torch.load('data/torch_para.pt')\n",
    "del torch_para[\"inner_product_layer.field_p\"]\n",
    "del torch_para[\"inner_product_layer.field_q\"]\n",
    "del torch_para[\"inner_product_layer.upper_triange_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name map\n",
    "name_map = {k:v for k,v in enumerate(sparse_feature_name)}\n",
    "# fuxi\n",
    "torch_linear_key = \\\n",
    "    ['dnn.dnn.%d.weight' % i for i in [0, 2, 4]] + \\\n",
    "    ['dnn.dnn.%d.bias' % i for i in [0, 2, 4]] + \\\n",
    "    ['fgcnn_layer.recombine_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.recombine_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.running_mean' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.running_var' % i for i in range(4)] \n",
    "torch_other_key = \\\n",
    "    ['embedding_layer.embedding_layer.embedding_layer.%s.weight' % v for v in name_map.values()] + \\\n",
    "    ['fg_embedding_layer.embedding_layer.embedding_layer.%s.weight' % v for v in name_map.values()] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.bias' % i for i in range(4)]\n",
    "# torch_inner_key = 'inner_product_layer.upper_triange_mask'\n",
    "\n",
    "# paddle\n",
    "paddle_linear_key = \\\n",
    "    ['dnn.dnn.%d.weight' % i for i in [0, 2, 4]] + \\\n",
    "    ['dnn.dnn.%d.bias' % i for i in [0, 2, 4]] + \\\n",
    "    ['fgcnn.recombine_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.recombine_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1._mean' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1._variance' % i for i in range(4)]\n",
    "paddle_other_key = \\\n",
    "    ['embedding.%d.embedding.weight' % k for k in name_map.keys()] + \\\n",
    "    ['fg_embedding.%d.embedding.weight' % k for k in name_map.keys()] + \\\n",
    "    ['fgcnn.conv_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1.bias' % i for i in range(4)]\n",
    "# paddle_inner_key = 'inner_product_layer.upper_triange_mask'\n",
    "\n",
    "# fuxi2paddle\n",
    "key_map = {key_t:key_p for key_t, key_p in zip(torch_other_key, paddle_other_key)}\n",
    "paddle_para = {key_map[k]:paddle.to_tensor(v.numpy()) for k, v in torch_para.items() if k in torch_other_key}\n",
    "for t, p in zip(torch_linear_key, paddle_linear_key):\n",
    "    if t in torch_para.keys():\n",
    "        paddle_para[p] = paddle.to_tensor(torch_para[t].T.numpy())\n",
    "# paddle_para[paddle_inner_key] = paddle.to_tensor(torch_para[torch_inner_key].numpy()).reshape((1,56,56)).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paddel\n",
    "p_fgcnn_layer = list(paddle_model.children())[2]\n",
    "p_recombine_layer = list(p_fgcnn_layer.children())[1]\n",
    "p_linear_layer = next(next(p_recombine_layer.children()).children())\n",
    "p_para = p_linear_layer.parameters()[0].numpy()\n",
    "# torch\n",
    "t_fgcnn_layer = list(torch_model.children())[2]\n",
    "t_recombine_layer = list(t_fgcnn_layer.children())[1]\n",
    "t_linear_layer = next(next(t_recombine_layer.children()).children())\n",
    "t_para = next(t_linear_layer.parameters()).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "torch_model.load_state_dict(torch_para)\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test\n",
    "in-out:\n",
    "- origin_input: ok\n",
    "- fg_input: ok\n",
    "- fgcnn_layer:\n",
    "    - conv:\n",
    "        - conv2d: ok\n",
    "        - batchnorm2d: ok\n",
    "        - tanh: ok\n",
    "        - maxpool2d: ok\n",
    "    - flatten: ok\n",
    "    - recombine: ok\n",
    "- inner_product: ok\n",
    "- dense_input: ok\n",
    "- dnn: ok\n",
    "\n",
    "para:\n",
    "- emb: ok\n",
    "- fg_emb: ok\n",
    "- conv: ok\n",
    "- recombine: ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_para = torch_model.state_dict()\n",
    "# fuxi2paddle\n",
    "key_map = {key_t:key_p for key_t, key_p in zip(torch_other_key, paddle_other_key)}\n",
    "paddle_para = {key_map[k]:paddle.to_tensor(v.numpy()) for k, v in torch_para.items() if k in torch_other_key}\n",
    "for t, p in zip(torch_linear_key, paddle_linear_key):\n",
    "    if t in torch_para.keys():\n",
    "        paddle_para[p] = paddle.to_tensor(torch_para[t].T.numpy())\n",
    "# paddle_para[paddle_inner_key] = paddle.to_tensor(torch_para[torch_inner_key].numpy()).reshape((1,56,56)).astype('int32')\n",
    "\n",
    "# torch\n",
    "torch_model.load_state_dict(torch_para)\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)\n",
    "\n",
    "torch_model.eval()\n",
    "paddle_model.eval()\n",
    "data, label = pipline_data[0][:-1], pipline_data[0][-1]\n",
    "# torch\n",
    "torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "# torch_out = torch_model.forward(torch_inputs)['y_pred'].detach().numpy()\n",
    "torch_out = torch_model.forward(torch_inputs).detach().numpy()\n",
    "# paddle\n",
    "paddle_out = paddle_model.forward(data).numpy()\n",
    "# diff\n",
    "diff = (torch_out - paddle_out).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/anaconda3/envs/fuxi_fgcnn/lib/python3.6/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    }
   ],
   "source": [
    "paddle_out = paddle_model.forward(data).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.scatter(range(len(diff)), diff/paddle_out.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chen/code/PaperReproduction/fgcnn/fuxi_pipline\n",
      "[2022/01/23 16:53:29] root INFO: logits: \n",
      "[2022/01/23 16:53:29] root INFO: logits: \n",
      "[2022/01/23 16:53:29] root INFO: \tmean diff: check passed: True, value: 6.254973783370588e-08\n",
      "[2022/01/23 16:53:29] root INFO: \tmean diff: check passed: True, value: 6.254973783370588e-08\n",
      "[2022/01/23 16:53:29] root INFO: diff check passed\n",
      "[2022/01/23 16:53:29] root INFO: diff check passed\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/PaperReproduction/fgcnn/fuxi_pipline\n",
    "torch_model.eval()\n",
    "paddle_model.eval()\n",
    "torch_forward = []\n",
    "paddle_forward = []\n",
    "for data in pipline_data:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # torch\n",
    "    torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "    torch_out = torch_model.forward(torch_inputs)\n",
    "    torch_forward.append(torch_out.detach().numpy())\n",
    "    # paddle\n",
    "    paddle_out = paddle_model.forward(data)\n",
    "    paddle_forward.append(paddle_out.numpy())\n",
    "\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"logits\", np.array(torch_forward))\n",
    "reprod_logger.save(\"step1/forward_torch.npy\")\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"logits\", np.array(paddle_forward))\n",
    "reprod_logger.save(\"step1/forward_paddle.npy\")\n",
    "# diff\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"step1/forward_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"step1/forward_paddle.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"diff/forward_diff.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/chen/code/PaperReproduction/fgcnn/fuxi_pipline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/anaconda3/envs/fuxi_fgcnn/lib/python3.6/site-packages/ipykernel_launcher.py:237: UserWarning: masked_select received a mask with dtype torch.uint8, this behavior is now deprecated,please use a mask with dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/TensorAdvancedIndexing.cpp:1356.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/01/23 16:34:59] root INFO: binary_cross_entropy: \n",
      "[2022/01/23 16:34:59] root INFO: binary_cross_entropy: \n",
      "[2022/01/23 16:34:59] root INFO: \tmean diff: check passed: True, value: 5.960464477539063e-08\n",
      "[2022/01/23 16:34:59] root INFO: \tmean diff: check passed: True, value: 5.960464477539063e-08\n",
      "[2022/01/23 16:34:59] root INFO: diff check passed\n",
      "[2022/01/23 16:34:59] root INFO: diff check passed\n"
     ]
    }
   ],
   "source": [
    "%cd ~/code/PaperReproduction/fgcnn/fuxi_pipline\n",
    "torch_model.eval()\n",
    "paddle_model.eval()\n",
    "torch_cost = []\n",
    "paddle_cost = []\n",
    "for data in pipline_data:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # torch\n",
    "    torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "    torch_out = torch_model.forward(torch_inputs)#['y_pred']\n",
    "    torch_cost.append(torch.nn.functional.binary_cross_entropy(torch_out, torch.Tensor([label]).reshape((1,1))).detach().numpy())\n",
    "    # paddle\n",
    "    paddle_out = paddle_model.forward(data)\n",
    "    paddle_cost.append(paddle.nn.functional.binary_cross_entropy(paddle_out, paddle.to_tensor(float(label)).reshape((1,1))).numpy()[0])\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"binary_cross_entropy\", np.array(torch_cost))\n",
    "reprod_logger.save(\"step2/metric_torch.npy\")\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"binary_cross_entropy\", np.array(paddle_cost))\n",
    "reprod_logger.save(\"step2/metric_paddle.npy\")\n",
    "# diff\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"step2/metric_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"step2/metric_paddle.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"diff/metric_diff.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "label = np.array([0, 0, 1, 1])\n",
    "pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "# torch\n",
    "print(roc_auc_score(label, pred))\n",
    "# paddle\n",
    "m = paddle.metric.Auc()\n",
    "\n",
    "class1_preds = pred.reshape(-1, 1)\n",
    "class0_preds = 1 - class1_preds\n",
    "\n",
    "preds = np.concatenate((class0_preds, class1_preds), axis=1)\n",
    "\n",
    "m.update(preds=preds, labels=label)\n",
    "print(m.accumulate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "torch_model.load_state_dict(torch_para)\n",
    "torch_model.eval()\n",
    "torch_optim = torch.optim.Adam(params=torch_model.parameters())\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)\n",
    "paddle_model.eval()\n",
    "paddle_optim = paddle.optimizer.Adam(parameters=paddle_model.parameters())\n",
    "# grad\n",
    "def save_paddle_hook_fn(grad):\n",
    "    global paddle_grad\n",
    "    paddle_grad.append(grad)\n",
    "\n",
    "def save_torch_hook_fn(grad):\n",
    "    global torch_grad\n",
    "    torch_grad.append(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/02/11 23:17:00] root INFO: loss: \n",
      "[2022/02/11 23:17:00] root INFO: \tmean diff: check passed: False, value: 3.460049629211426e-05\n",
      "[2022/02/11 23:17:00] root INFO: diff check failed\n"
     ]
    }
   ],
   "source": [
    "t_out = []\n",
    "p_out = []\n",
    "torch_loss = []\n",
    "paddle_loss = []\n",
    "labels = []\n",
    "torch_grad, paddle_grad = [], []\n",
    "for data in pipline_data[:2]:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # torch\n",
    "    torch_optim.zero_grad()\n",
    "    torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "    torch_out = torch_model.forward(torch_inputs)#['y_pred']\n",
    "    t_loss = torch.nn.functional.binary_cross_entropy(torch_out, torch.Tensor([label]).reshape((1,1)))\n",
    "    # t_loss.register_hook(lambda grad: print('t:', grad.detach().numpy()))\n",
    "    t_loss.backward()\n",
    "    # for name, tensor in torch_model.named_parameters():\n",
    "    #     grad = tensor.grad.numpy()\n",
    "    #     torch_grad.append((name, grad))\n",
    "    torch_optim.step()\n",
    "    # paddle\n",
    "    paddle_optim.clear_grad()\n",
    "    paddle_out = paddle_model.forward(data)\n",
    "    p_loss = paddle.nn.functional.binary_cross_entropy(paddle_out, paddle.to_tensor(float(label)).reshape((1,1)))\n",
    "    # p_loss.register_hook(lambda grad: print('p:', grad.numpy()[0]))\n",
    "    p_loss.backward()\n",
    "    # for name, tensor in paddle_model.named_parameters():\n",
    "    #     grad = tensor.grad\n",
    "    #     paddle_grad.append((name, grad))\n",
    "    paddle_optim.step()\n",
    "    # test\n",
    "    t_out.append(torch_out.detach().numpy())\n",
    "    p_out.append(paddle_out.numpy())\n",
    "    torch_loss.append(t_loss.detach().numpy())\n",
    "    paddle_loss.append(p_loss.numpy())\n",
    "    labels.append(label)\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"loss\", np.array(torch_loss))\n",
    "reprod_logger.save(\"step4/bp_align_torch.npy\")\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"loss\", np.array(paddle_loss).reshape(-1))\n",
    "reprod_logger.save(\"step4/bp_align_paddle.npy\")\n",
    "# diff\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"step4/bp_align_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"step4/bp_align_paddle.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"diff/bp_align_diff.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe0a58fb5f8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "d = (np.array(t_out) - np.array(p_out)).ravel()\n",
    "plt.scatter(range(len(d)), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUy0lEQVR4nO3bf0xV9/3H8deF64/gvSL3XoGxmaVlmkXF0XK7OZZMLDddF9KWYLs0dl2cfzldV1w2nTo7V6OlzZSu4FKzEGITstIRa5f+0aaUYTeJDmqvHTVpRVwmAYv3XmT8iBO45/tHvyMydFzvuXALn+fjv3PP59zzfqHcV845F4dlWZYAAMZKSfYAAIDkoggAwHAUAQAYjiIAAMNRBABgOIoAAAznTPYA8eru7o7rOJ/Pp1AolOBpPt/IbAbTMpuWV7KfOScn55avc0UAAIajCADAcBQBABiOIgAAw1EEAGA4igAADEcRAIDhKAIAMBxFAACGowgAwHAUAQAYjiIAAMNRBABgOIoAAAxHEQCA4SgCADAcRQAAhqMIAMBwFAEAGI4iAADDUQQAYDiKAAAMRxEAgOEoAgAwHEUAAIZzJuJNgsGgamtrFY1GVVxcrNLS0gn7R0ZGVF1drc7OTrndbpWXlyszM3N8fygU0vbt2/XYY4/p4YcfTsRIAIAY2b4iiEajqqmp0e7du1VZWalTp06pq6trwpqmpiYtWrRIVVVVKikpUV1d3YT9x44d0z333GN3FABAHGwXQUdHh7Kzs5WVlSWn06nCwkK1trZOWNPW1qaioiJJ0tq1a9Xe3i7LsiRJf/vb35SZmakvfelLdkcBAMTB9q2hSCQir9c7vu31enXhwoXbrklNTVVaWpoGBgY0f/58vfHGG9q7d6/+9Kc//c/zNDY2qrGxUZJUUVEhn88X17xOpzPuY2crMpvBtMym5ZWmL3NCnhHE67XXXlNJSYkWLlw45dpAIKBAIDC+HQqF4jqnz+eL+9jZisxmMC2zaXkl+5lzcnJu+brtIvB4PAqHw+Pb4XBYHo/nlmu8Xq/GxsY0PDwst9utjo4OnTlzRnV1dRoaGpLD4dD8+fP14IMP2h0LABAj20WQm5urnp4e9fb2yuPxqKWlRT/5yU8mrCkoKFBzc7NWrFih06dPa9WqVXI4HHr22WfH17z22mtauHAhJQAAM8x2EaSmpmrz5s06cOCAotGo1q9fr2XLlqm+vl65ubny+/26//77VV1draeeekoul0vl5eUJGB0AkAgO6z9f35lluru74zqO+4pmIPPcZ1peafqeEfCXxQBgOIoAAAxHEQCA4SgCADAcRQAAhqMIAMBwFAEAGI4iAADDUQQAYDiKAAAMRxEAgOEoAgAwHEUAAIajCADAcBQBABiOIgAAw1EEAGA4igAADEcRAIDhKAIAMBxFAACGowgAwHAUAQAYjiIAAMNRBABgOIoAAAxHEQCA4SgCADAcRQAAhqMIAMBwzkS8STAYVG1traLRqIqLi1VaWjph/8jIiKqrq9XZ2Sm3263y8nJlZmbqww8/VF1dnUZHR+V0OvXkk09q9erViRgJABAj21cE0WhUNTU12r17tyorK3Xq1Cl1dXVNWNPU1KRFixapqqpKJSUlqqurkyS53W7t3LlThw4d0rZt21RVVWV3HADAHbJdBB0dHcrOzlZWVpacTqcKCwvV2to6YU1bW5uKiookSWvXrlV7e7ssy9Jdd90lj8cjSVq2bJlu3LihkZERuyMBAO6A7SKIRCLyer3j216vV5FI5LZrUlNTlZaWpoGBgQlrzpw5o7vvvlvz5s2zOxIA4A4k5BmBXZcvX1ZdXZ327Nlz2zWNjY1qbGyUJFVUVMjn88V1LqfTGfexsxWZzWBaZtPyStOX2XYReDwehcPh8e1wODx+u+e/13i9Xo2NjWl4eFhut3t8/W9+8xtt27ZN2dnZtz1PIBBQIBAY3w6FQnHN6/P54j52tiKzGUzLbFpeyX7mnJycW75u+9ZQbm6uenp61Nvbq9HRUbW0tMjv909YU1BQoObmZknS6dOntWrVKjkcDg0NDamiokIbN27UV7/6VbujAADiYPuKIDU1VZs3b9aBAwcUjUa1fv16LVu2TPX19crNzZXf79f999+v6upqPfXUU3K5XCovL5ckvfXWW7py5YoaGhrU0NAgSfrlL3+p9PR0u2MBAGLksCzLSvYQ8eju7o7rOC4nzUDmuc+0vNLn+NYQAGB2owgAwHAUAQAYjiIAAMNRBABgOIoAAAxHEQCA4SgCADAcRQAAhqMIAMBwFAEAGI4iAADDUQQAYDiKAAAMRxEAgOEoAgAwHEUAAIajCADAcBQBABiOIgAAw1EEAGA4igAADEcRAIDhKAIAMBxFAACGowgAwHAUAQAYjiIAAMNRBABgOIoAAAxHEQCA4ZyJeJNgMKja2lpFo1EVFxertLR0wv6RkRFVV1ers7NTbrdb5eXlyszMlCS9/vrrampqUkpKin74wx8qPz8/ESNNEr16RXqjTpGhAUUXuaVHnlDK0uxpORcAJNJ0f37ZviKIRqOqqanR7t27VVlZqVOnTqmrq2vCmqamJi1atEhVVVUqKSlRXV2dJKmrq0stLS06fPiw9uzZo5qaGkWjUbsjTZ7x6hVZlc/IOnNSI+1nZZ05Kavymc9+uADwOTYTn1+2i6Cjo0PZ2dnKysqS0+lUYWGhWltbJ6xpa2tTUVGRJGnt2rVqb2+XZVlqbW1VYWGh5s2bp8zMTGVnZ6ujo8PuSJO9USf99w/t/xsWAD7XZuDzy/atoUgkIq/XO77t9Xp14cKF265JTU1VWlqaBgYGFIlEtHz58vF1Ho9HkUjkludpbGxUY2OjJKmiokI+ny/2GYcGNHKL151DA/LcwfvMVk6n845+XnMBmec+U/LOxOdXQp4RzIRAIKBAIDC+HQqFYj42ush9y9dHF7nv6H1mK5/PZ0TOm5F57jMlbyI/v3Jycm75uu1bQx6PR+FweHw7HA7L4/Hcds3Y2JiGh4fldrsnHRuJRCYdmxCPPCH994OVpdmfvQ4An2cz8Plluwhyc3PV09Oj3t5ejY6OqqWlRX6/f8KagoICNTc3S5JOnz6tVatWyeFwyO/3q6WlRSMjI+rt7VVPT4++8pWv2B1pkpSl2XJsf1aOb6zTvNX3yvGNdXJsf5ZvDQH43JuJzy+HZVmW3Tc5e/asjh07pmg0qvXr16usrEz19fXKzc2V3+/XjRs3VF1drUuXLsnlcqm8vFxZWVmSpOPHj+vPf/6zUlJStGnTJt1zzz0xnbO7uzuuWU25nLwZmc1gWmbT8kr2M9/u1lBCiiAZKILYkdkMpmU2La80fUXAXxYDgOEoAgAwHEUAAIajCADAcBQBABiOIgAAw1EEAGA4igAADEcRAIDhKAIAMBxFAACGowgAwHAUAQAYjiIAAMNRBABgOIoAAAxHEQCA4SgCADAcRQAAhqMIAMBwFAEAGI4iAADDUQQAYDiKAAAMRxEAgOEoAgAwHEUAAIajCADAcBQBABiOIgAAwzntHDw4OKjKykpdvXpVS5cu1fbt2+VyuSata25u1vHjxyVJZWVlKioq0r///W8dPnxYn376qVJSUlRQUKAnnnjCzjgAgDjYuiI4ceKE8vLy9NJLLykvL08nTpyYtGZwcFANDQ06ePCgDh48qIaGBg0ODkqSHnroIb344ot64YUX9PHHH+uDDz6wMw4AIA62iqC1tVXr1q2TJK1bt06tra2T1gSDQa1Zs0Yul0sul0tr1qxRMBjUggULtHr1akmS0+nUXXfdpXA4bGccAEAcbBVBf3+/MjIyJElLlixRf3//pDWRSERer3d82+PxKBKJTFgzNDSk999/X3l5eXbGAQDEYcpnBPv379e1a9cmvf74449P2HY4HHI4HHc8wNjYmH7729/qu9/9rrKysm67rrGxUY2NjZKkiooK+Xy+Oz6X9NnVR7zHzlZkNoNpmU3LK01f5imLYO/evbfdl56err6+PmVkZKivr0+LFy+etMbj8ej8+fPj25FIRCtXrhzfPnr0qLKzs1VSUvI/5wgEAgoEAuPboVBoqtFvyefzxX3sbEVmM5iW2bS8kv3MOTk5t3zd1q0hv9+vkydPSpJOnjyp++67b9Ka/Px8nTt3ToODgxocHNS5c+eUn58vSXr11Vc1PDysTZs22RkDAGCDra+PlpaWqrKyUk1NTeNfH5Wkixcv6p133tGWLVvkcrm0YcMG7dq1S5L06KOPyuVyKRwO6/jx4/riF7+onTt3SpIefPBBFRcX24wEALgTDsuyrGQPEY/u7u64juNy0gxknvtMyyt9Tm8NAQBmP4oAAAxHEQCA4SgCADAcRQAAhqMIAMBwFAEAGI4iAADDUQQAYDiKAAAMRxEAgOEoAgAwHEUAAIajCADAcBQBABiOIgAAw1EEAGA4igAADEcRAIDhKAIAMBxFAACGowgAwHAUAQAYjiIAAMNRBABgOIoAAAxHEQCA4SgCADAcRQAAhqMIAMBwFAEAGM5p5+DBwUFVVlbq6tWrWrp0qbZv3y6XyzVpXXNzs44fPy5JKisrU1FR0YT9zz//vHp7e3Xo0CE74wAA4mDriuDEiRPKy8vTSy+9pLy8PJ04cWLSmsHBQTU0NOjgwYM6ePCgGhoaNDg4OL7/zJkzWrhwoZ0xAAA22CqC1tZWrVu3TpK0bt06tba2TloTDAa1Zs0auVwuuVwurVmzRsFgUJJ0/fp1vfnmm9qwYYOdMQAANti6NdTf36+MjAxJ0pIlS9Tf3z9pTSQSkdfrHd/2eDyKRCKSpFdffVUPPfSQ5s+fP+W5Ghsb1djYKEmqqKiQz+eLa2an0xn3sbMVmc1gWmbT8krTl3nKIti/f7+uXbs26fXHH398wrbD4ZDD4Yj5xP/4xz/06aefatOmTert7Z1yfSAQUCAQGN8OhUIxn+tmPp8v7mNnKzKbwbTMpuWV7GfOycm55etTFsHevXtvuy89PV19fX3KyMhQX1+fFi9ePGmNx+PR+fPnx7cjkYhWrlypTz75RJ2dndq2bZvGxsbU39+vffv2ad++fTHEAQAkiq1bQ36/XydPnlRpaalOnjyp++67b9Ka/Px8/eEPfxh/QHzu3Dlt3LhRLpdLDzzwgCSpt7dXzz//PCUAAElgqwhKS0tVWVmppqam8a+PStLFixf1zjvvaMuWLXK5XNqwYYN27dolSXr00Udv+RVTAEByOCzLspI9RDy6u7vjOo77imYg89xnWl5p+p4R8JfFAGA4igAADEcRAIDhKAIAMBxFAACGowgAwHAUAQAYjiIAAMNRBABgOIoAAAxHEQCA4SgCADAcRQAAhqMIAMBwFAEAGI4iAADDUQQAYDiKAAAMRxEAgOEoAgAwHEUAAIajCADAcBQBABiOIgAAwzksy7KSPQQAIHmMuyL4xS9+kewRZhyZzWBaZtPyStOX2bgiAABMRBEAgOGMK4JAIJDsEWYcmc1gWmbT8krTl5mHxQBgOOOuCAAAE1EEAGA4Z7IHmC7BYFC1tbWKRqMqLi5WaWnphP0jIyOqrq5WZ2en3G63ysvLlZmZmZxhE2CqvG+++abeffddpaamavHixfrRj36kpUuXJmfYBJkq83+cPn1ahw8f1nPPPafc3NyZHTLBYsnc0tKiP/7xj3I4HPryl7+sp59+euYHTaCpModCIR05ckRDQ0OKRqPauHGj7r333uQMmwC/+93vdPbsWaWnp+vQoUOT9luWpdraWn3wwQdasGCBtm7dqrvvvtveSa05aGxszPrxj39sXblyxRoZGbF+9rOfWZcvX56w5q233rKOHj1qWZZl/fWvf7UOHz6cjFETIpa8f//7363r169blmVZb7/99qzOa1mxZbYsyxoeHraeeeYZa/fu3VZHR0cSJk2cWDJ3d3dbP//5z62BgQHLsizr2rVryRg1YWLJ/PLLL1tvv/22ZVmWdfnyZWvr1q3JGDVhPvroI+vixYvWT3/601vuf//9960DBw5Y0WjU+vjjj61du3bZPuecvDXU0dGh7OxsZWVlyel0qrCwUK2trRPWtLW1qaioSJK0du1atbe3y5qlz81jybt69WotWLBAkrR8+XJFIpFkjJowsWSWpPr6ej3yyCOaN29eEqZMrFgyv/vuu/rOd74jl8slSUpPT0/GqAkTS2aHw6Hh4WFJ0vDwsDIyMpIxasKsXLly/N/vVtra2vTtb39bDodDK1as0NDQkPr6+mydc04WQSQSkdfrHd/2er2TPvhuXpOamqq0tDQNDAzM6JyJEkvemzU1NSk/P38GJps+sWTu7OxUKBSa1bcJbhZL5u7ubvX09Gjv3r3as2ePgsHgDE+ZWLFkfuyxx/SXv/xFW7Zs0XPPPafNmzfP9JgzKhKJyOfzjW9P9fseizlZBLi99957T52dnXr44YeTPcq0ikajeuWVV/SDH/wg2aPMqGg0qp6eHv3qV7/S008/raNHj2poaCjZY02rU6dOqaioSC+//LJ27dqlqqoqRaPRZI81q8zJIvB4PAqHw+Pb4XBYHo/ntmvGxsY0PDwst9s9o3MmSix5JenDDz/U66+/rh07dsz6WyVTZb5+/bouX76sX//619q2bZsuXLigF154QRcvXkzGuAkR6/9rv98vp9OpzMxMfeELX1BPT89Mj5owsWRuamrSN7/5TUnSihUrNDIyMmuv7mPh8XgUCoXGt2/3+34n5mQR5ObmqqenR729vRodHVVLS4v8fv+ENQUFBWpubpb02bdKVq1aJYfDkYRp7Ysl76VLl/T73/9eO3bsmPX3jaWpM6elpammpkZHjhzRkSNHtHz5cu3YsWNWf2soln/nr3/96/roo48kSf/617/U09OjrKysZIybELFk9vl8am9vlyR1dXVpZGREixcvTsa4M8Lv9+u9996TZVn65JNPlJaWZvu5yJz9y+KzZ8/q2LFjikajWr9+vcrKylRfX6/c3Fz5/X7duHFD1dXVunTpklwul8rLy2f1L8xUeffv369//vOfWrJkiaTPfnl27tyZ3KFtmirzzfbt26cnn3xyVheBNHVmy7L0yiuvKBgMKiUlRWVlZfrWt76V7LFtmSpzV1eXjh49quvXr0uSvv/97+trX/takqeO34svvqjz589rYGBA6enp+t73vqfR0VFJ0gMPPCDLslRTU6Nz585p/vz52rp1q+3/13O2CAAAsZmTt4YAALGjCADAcBQBABiOIgAAw1EEAGA4igAADEcRAIDh/g+c0ftx1jl7jQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-00018fd1c1a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m83\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaddle_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m83\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "d = np.array(torch_loss) - np.array(paddle_loss).reshape(-1)\n",
    "plt.scatter(range(len(d)), d)\n",
    "plt.show()\n",
    "torch_loss[83], paddle_loss[83]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/anaconda3/envs/fuxi_fgcnn/lib/python3.6/site-packages/paddle/nn/layer/norm.py:653: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/02/11 23:25:03] root INFO: train: \n",
      "[2022/02/11 23:25:03] root INFO: train: \n",
      "[2022/02/11 23:25:03] root INFO: train: \n",
      "[2022/02/11 23:25:03] root INFO: train: \n",
      "[2022/02/11 23:25:03] root INFO: \tmean diff: check passed: False, value: 0.8821567296981812\n",
      "[2022/02/11 23:25:03] root INFO: \tmean diff: check passed: False, value: 0.8821567296981812\n",
      "[2022/02/11 23:25:03] root INFO: \tmean diff: check passed: False, value: 0.8821567296981812\n",
      "[2022/02/11 23:25:03] root INFO: \tmean diff: check passed: False, value: 0.8821567296981812\n",
      "[2022/02/11 23:25:03] root INFO: diff check failed\n",
      "[2022/02/11 23:25:03] root INFO: diff check failed\n",
      "[2022/02/11 23:25:03] root INFO: diff check failed\n",
      "[2022/02/11 23:25:03] root INFO: diff check failed\n"
     ]
    }
   ],
   "source": [
    "# torch\n",
    "torch_model.load_state_dict(torch_para)\n",
    "torch_model.train()\n",
    "torch_optim = torch.optim.Adam(\n",
    "            params=torch_model.parameters(),\n",
    "            lr=0.001)\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)\n",
    "paddle_model.train()\n",
    "paddle_optim = paddle.optimizer.Adam(\n",
    "            parameters=paddle_model.parameters(),\n",
    "            learning_rate=0.001)\n",
    "t_out = []\n",
    "p_out = []\n",
    "torch_loss = []\n",
    "paddle_loss = []\n",
    "for epoch in range(2):\n",
    "    for data in pipline_data:\n",
    "        data, label = data[:-1], data[-1]\n",
    "        # torch\n",
    "        torch_optim.zero_grad()\n",
    "        torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "        torch_out = torch_model.forward(torch_inputs)#['y_pred']\n",
    "        t_loss = torch.nn.functional.binary_cross_entropy(torch_out, torch.Tensor([label]).reshape((1,1)))\n",
    "        # t_loss.register_hook(lambda grad: print('t:', grad.detach().numpy()))\n",
    "        t_loss.backward()\n",
    "        torch_optim.step()\n",
    "        # paddle\n",
    "        paddle_optim.clear_grad()\n",
    "        paddle_out = paddle_model.forward(data)\n",
    "        p_loss = paddle.nn.functional.binary_cross_entropy(paddle_out, paddle.to_tensor(float(label)).reshape((1,1)))\n",
    "        # p_loss.register_hook(lambda grad: print('p:', grad.numpy()[0]))\n",
    "        p_loss.backward()\n",
    "        paddle_optim.step()\n",
    "        # test\n",
    "        t_out.append(torch_out.detach().numpy())\n",
    "        p_out.append(paddle_out.numpy())\n",
    "        torch_loss.append(t_loss.detach().numpy())\n",
    "        paddle_loss.append(p_loss.numpy())\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"train\", np.array(torch_loss))\n",
    "reprod_logger.save(\"step5/train_torch.npy\")\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"train\", np.array(paddle_loss))\n",
    "reprod_logger.save(\"step5/train_paddle.npy\")\n",
    "# step 5\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"step5/train_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"step5/train_paddle.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"diff/loss_diff.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "d = (np.array(t_out) - np.array(p_out)).ravel()\n",
    "plt.scatter(range(len(d)), d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d = np.array(torch_loss) - np.array(paddle_loss).reshape(-1)\n",
    "plt.scatter(range(len(d)), d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022/02/11 23:34:48] root INFO: train: \n",
      "[2022/02/11 23:34:48] root INFO: \tmean diff: check passed: True, value: 0.0\n",
      "[2022/02/11 23:34:48] root INFO: diff check passed\n"
     ]
    }
   ],
   "source": [
    "# torch1\n",
    "torch_model1 = fuxi_FGCNN(feature_map, **params)\n",
    "torch_model1.load_state_dict(torch_para)\n",
    "torch_model1.train()\n",
    "torch_optim1 = torch.optim.Adam(\n",
    "            params=torch_model1.parameters(),\n",
    "            lr=0.001)\n",
    "# torch2\n",
    "torch_model2 = fuxi_FGCNN(feature_map, **params)\n",
    "torch_model2.load_state_dict(torch_para)\n",
    "torch_model2.train()\n",
    "torch_optim2 = torch.optim.Adam(\n",
    "            params=torch_model2.parameters(),\n",
    "            lr=0.001)\n",
    "t1_outs = []\n",
    "t2_outs = []\n",
    "t1_losses = []\n",
    "t2_losses = []\n",
    "for epoch in range(2):\n",
    "    for data in pipline_data:\n",
    "        data, label = data[:-1], data[-1]\n",
    "        # torch1\n",
    "        torch_optim1.zero_grad()\n",
    "        torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "        t1_out = torch_model1.forward(torch_inputs)#['y_pred']\n",
    "        t1_loss = torch.nn.functional.binary_cross_entropy(t1_out, torch.Tensor([label]).reshape((1,1)))\n",
    "        # t_loss.register_hook(lambda grad: print('t:', grad.detach().numpy()))\n",
    "        t1_loss.backward()\n",
    "        torch_optim1.step()\n",
    "        # torch2\n",
    "        torch_optim2.zero_grad()\n",
    "        torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "        t2_out = torch_model2.forward(torch_inputs)#['y_pred']\n",
    "        t2_loss = torch.nn.functional.binary_cross_entropy(t2_out, torch.Tensor([label]).reshape((1,1)))\n",
    "        # t_loss.register_hook(lambda grad: print('t:', grad.detach().numpy()))\n",
    "        t2_loss.backward()\n",
    "        torch_optim2.step()\n",
    "        # test\n",
    "        t1_outs.append(t1_out.detach().numpy())\n",
    "        t2_outs.append(t2_out.detach().numpy())\n",
    "        t1_losses.append(t1_loss.detach().numpy())\n",
    "        t2_losses.append(t2_loss.detach().numpy())\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"train\", np.array(t1_losses))\n",
    "reprod_logger.save(\"test/train_t1.npy\")\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"train\", np.array(t2_losses))\n",
    "reprod_logger.save(\"test/train_t2.npy\")\n",
    "# step 5\n",
    "diff_helper = ReprodDiffHelper()\n",
    "t1_info = diff_helper.load_info(\"test/train_t1.npy\")\n",
    "t2_info = diff_helper.load_info(\"test/train_t2.npy\")\n",
    "\n",
    "diff_helper.compare_info(t1_info, t2_info)\n",
    "\n",
    "diff_helper.report(path=\"diff/test_diff.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "d = (np.array(t1_outs) - np.array(t2_outs)).ravel()\n",
    "plt.scatter(range(len(d)), d)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "762831eace365ee16f120c22ed7d5689be70c5a8e9076c823f0ed1712f1c33fd"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('fuxictr_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
