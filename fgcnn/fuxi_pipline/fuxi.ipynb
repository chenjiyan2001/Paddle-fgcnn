{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install h5py\n",
    "!pip install Pyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:56:47,773 P75318 INFO {\n",
      "    \"batch_norm\": \"False\",\n",
      "    \"batch_size\": \"1\",\n",
      "    \"channels\": \"[14, 16, 18, 20]\",\n",
      "    \"data_block_size\": \"-1\",\n",
      "    \"data_root\": \"../data/\",\n",
      "    \"dataset_id\": \"taobao_tiny\",\n",
      "    \"dnn_hidden_units\": \"[128, 64]\",\n",
      "    \"embedding_dim\": \"10\",\n",
      "    \"embedding_regularizer\": \"0\",\n",
      "    \"epochs\": \"3\",\n",
      "    \"every_x_epochs\": \"1\",\n",
      "    \"feature_cols\": \"[{'name': ['userid', 'adgroup_id', 'pid', 'cate_id', 'campaign_id', 'customer', 'brand', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level', 'pvalue_level', 'shopping_level', 'occupation'], 'active': True, 'dtype': 'str', 'type': 'categorical'}]\",\n",
      "    \"gpu\": \"-1\",\n",
      "    \"hidden_activations\": \"relu\",\n",
      "    \"kernel_heights\": \"[7, 7, 7, 7]\",\n",
      "    \"label_col\": \"{'name': 'clk', 'dtype': <class 'float'>}\",\n",
      "    \"learning_rate\": \"0.001\",\n",
      "    \"loss\": \"binary_crossentropy\",\n",
      "    \"metrics\": \"['logloss', 'AUC']\",\n",
      "    \"min_categr_count\": \"1\",\n",
      "    \"model_id\": \"FGCNN_demo\",\n",
      "    \"model_root\": \"../checkpoints/\",\n",
      "    \"monitor\": \"AUC\",\n",
      "    \"monitor_mode\": \"max\",\n",
      "    \"net_dropout\": \"0\",\n",
      "    \"net_regularizer\": \"0\",\n",
      "    \"num_workers\": \"1\",\n",
      "    \"optimizer\": \"adam\",\n",
      "    \"patience\": \"2\",\n",
      "    \"pickle_feature_encoder\": \"True\",\n",
      "    \"pooling_sizes\": \"[2, 2, 2, 2]\",\n",
      "    \"recombined_channels\": \"[3, 3, 3, 3]\",\n",
      "    \"save_best_only\": \"True\",\n",
      "    \"seed\": \"2019\",\n",
      "    \"shuffle\": \"True\",\n",
      "    \"task\": \"binary_classification\",\n",
      "    \"test_data\": \"../data/tiny_data/test_sample.csv\",\n",
      "    \"train_data\": \"../data/tiny_data/train_sample.csv\",\n",
      "    \"use_hdf5\": \"True\",\n",
      "    \"valid_data\": \"../data/tiny_data/valid_sample.csv\",\n",
      "    \"verbose\": \"1\",\n",
      "    \"version\": \"pytorch\"\n",
      "}\n",
      "2022-05-23 17:56:47,776 P75318 INFO Set up feature encoder...\n",
      "2022-05-23 17:56:47,777 P75318 INFO Reading file: ../data/tiny_data/train_sample.csv\n",
      "2022-05-23 17:56:47,784 P75318 INFO Reading file: ../data/tiny_data/valid_sample.csv\n",
      "2022-05-23 17:56:47,789 P75318 INFO Reading file: ../data/tiny_data/test_sample.csv\n",
      "2022-05-23 17:56:47,794 P75318 INFO Preprocess feature columns...\n",
      "2022-05-23 17:56:47,802 P75318 INFO Fit feature encoder...\n",
      "2022-05-23 17:56:47,803 P75318 INFO Processing column: {'name': 'userid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,804 P75318 INFO Processing column: {'name': 'adgroup_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,805 P75318 INFO Processing column: {'name': 'pid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,806 P75318 INFO Processing column: {'name': 'cate_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,808 P75318 INFO Processing column: {'name': 'campaign_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,809 P75318 INFO Processing column: {'name': 'customer', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,810 P75318 INFO Processing column: {'name': 'brand', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,811 P75318 INFO Processing column: {'name': 'cms_segid', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,812 P75318 INFO Processing column: {'name': 'cms_group_id', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,814 P75318 INFO Processing column: {'name': 'final_gender_code', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,815 P75318 INFO Processing column: {'name': 'age_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,816 P75318 INFO Processing column: {'name': 'pvalue_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,817 P75318 INFO Processing column: {'name': 'shopping_level', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,818 P75318 INFO Processing column: {'name': 'occupation', 'active': True, 'dtype': 'str', 'type': 'categorical'}\n",
      "2022-05-23 17:56:47,818 P75318 INFO Set feature index...\n",
      "2022-05-23 17:56:47,819 P75318 INFO Pickle feature_encode: ../data/taobao_tiny/feature_encoder.pkl\n",
      "2022-05-23 17:56:47,827 P75318 INFO Save feature_map to json: ../data/taobao_tiny/feature_map.json\n",
      "2022-05-23 17:56:47,829 P75318 INFO Set feature encoder done.\n",
      "2022-05-23 17:56:47,829 P75318 INFO Transform feature columns...\n",
      "2022-05-23 17:56:47,833 P75318 INFO Saving data to h5: ../data/taobao_tiny/train.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hy-tmp/Paddle-fgcnn-version1/fgcnn/fuxi_pipline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-23 17:56:48,014 P75318 INFO Preprocess feature columns...\n",
      "2022-05-23 17:56:48,024 P75318 INFO Transform feature columns...\n",
      "2022-05-23 17:56:48,027 P75318 INFO Saving data to h5: ../data/taobao_tiny/valid.h5\n",
      "2022-05-23 17:56:48,141 P75318 INFO Preprocess feature columns...\n",
      "2022-05-23 17:56:48,148 P75318 INFO Transform feature columns...\n",
      "2022-05-23 17:56:48,151 P75318 INFO Saving data to h5: ../data/taobao_tiny/test.h5\n",
      "2022-05-23 17:56:48,268 P75318 INFO Transform csv data to h5 done.\n",
      "2022-05-23 17:56:48,269 P75318 INFO Loading data...\n",
      "2022-05-23 17:56:48,270 P75318 INFO Loading data from h5: ../data/taobao_tiny/train.h5\n",
      "2022-05-23 17:56:48,272 P75318 INFO Loading data from h5: ../data/taobao_tiny/valid.h5\n",
      "2022-05-23 17:56:48,274 P75318 INFO Train samples: total/100, pos/4, neg/96, ratio/4.00%, blocks/1\n",
      "2022-05-23 17:56:48,275 P75318 INFO Validation samples: total/100, pos/4, neg/96, ratio/4.00%, blocks/1\n",
      "2022-05-23 17:56:48,276 P75318 INFO Loading train data done.\n"
     ]
    }
   ],
   "source": [
    "%cd fgcnn/fuxi_pipline\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from fuxictr import datasets\n",
    "from fuxictr.datasets.taobao import FeatureEncoder\n",
    "from fuxictr.features import FeatureMap\n",
    "from fuxictr.utils import load_config, set_logger, print_to_json\n",
    "from fuxictr.pytorch.models import FGCNN\n",
    "from fuxictr.pytorch.torch_utils import seed_everything\n",
    "import torch\n",
    "\n",
    "feature_cols = [{'name': [\"userid\",\"adgroup_id\",\"pid\",\"cate_id\",\"campaign_id\",\"customer\",\"brand\",\"cms_segid\",\n",
    "                            \"cms_group_id\",\"final_gender_code\",\"age_level\",\"pvalue_level\",\"shopping_level\",\"occupation\"],\n",
    "                    'active': True, 'dtype': 'str', 'type': 'categorical'}]\n",
    "label_col = {'name': 'clk', 'dtype': float}\n",
    "\n",
    "params = {'model_id': 'FGCNN_demo',\n",
    "            'dataset_id': 'taobao_tiny',\n",
    "            'train_data': '../data/tiny_data/train_sample.csv',\n",
    "            'valid_data': '../data/tiny_data/valid_sample.csv',\n",
    "            'test_data': '../data/tiny_data/test_sample.csv',\n",
    "            'model_root': '../checkpoints/',\n",
    "            'data_root': '../data/',\n",
    "            'feature_cols': feature_cols,\n",
    "            'label_col': label_col,\n",
    "            'embedding_regularizer': 0,\n",
    "            'net_regularizer': 0,\n",
    "            'dnn_hidden_units': [128, 64],\n",
    "            \"channels\": [14, 16, 18, 20],\n",
    "            \"kernel_heights\": [7, 7, 7, 7],\n",
    "            'hidden_activations': \"relu\",\n",
    "            'learning_rate': 1e-3,\n",
    "            'net_dropout': 0,\n",
    "            'batch_norm': False,\n",
    "            'optimizer': 'adam',\n",
    "            'task': 'binary_classification',\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'metrics': ['logloss', 'AUC'],\n",
    "            'min_categr_count': 1,\n",
    "            'embedding_dim': 10,\n",
    "            \"pooling_sizes\": [2, 2, 2, 2],\n",
    "            \"recombined_channels\": [3, 3, 3, 3],\n",
    "            'batch_size': 1,\n",
    "            'epochs': 3,\n",
    "            'shuffle': True,\n",
    "            'seed': 2019,\n",
    "            'monitor': 'AUC',\n",
    "            'monitor_mode': 'max',\n",
    "            'use_hdf5': True,\n",
    "            'pickle_feature_encoder': True,\n",
    "            'save_best_only': True,\n",
    "            'every_x_epochs': 1,\n",
    "            'patience': 2,\n",
    "            'num_workers': 1,\n",
    "            'data_block_size': -1,\n",
    "            'verbose': 1,\n",
    "            'version': 'pytorch',\n",
    "            'gpu': -1}\n",
    "\n",
    "set_logger(params)\n",
    "logging.info(print_to_json(params))\n",
    "seed_everything(seed=params['seed'])\n",
    "\n",
    "# Set feature_encoder that defines how to preprocess data\n",
    "feature_encoder = FeatureEncoder(feature_cols, \n",
    "                                    label_col, \n",
    "                                    dataset_id=params['dataset_id'], \n",
    "                                    data_root=params[\"data_root\"])\n",
    "# Build dataset from csv to h5\n",
    "datasets.build_dataset(feature_encoder, \n",
    "                        train_data=params[\"train_data\"], \n",
    "                        valid_data=params[\"valid_data\"], \n",
    "                        test_data=params[\"test_data\"])\n",
    "# Get feature_map that defines feature specs\n",
    "feature_map = feature_encoder.feature_map\n",
    "# Get train and validation data generator from h5\n",
    "data_dir = os.path.join(params['data_root'], params['dataset_id'])\n",
    "train_gen, valid_gen = datasets.h5_generator(feature_map, \n",
    "                                                stage='train', \n",
    "                                                train_data=os.path.join(data_dir, 'train.h5'),\n",
    "                                                valid_data=os.path.join(data_dir, 'valid.h5'),\n",
    "                                                batch_size=params['batch_size'],\n",
    "                                                shuffle=params['shuffle'])                                      \n",
    "torch_model = FGCNN(feature_map, **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## FuxiCTR-FGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hy-tmp/Paddle-fgcnn-version1/fgcnn/fuxi_pipline\n"
     ]
    }
   ],
   "source": [
    "%cd fgcnn/fuxi_pipline\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch\n",
    "from fuxictr.pytorch.models.base_model import BaseModel\n",
    "from fuxictr.pytorch.layers import EmbeddingLayer#, InnerProductLayer\n",
    "from fuxictr.pytorch.torch_utils import set_activation\n",
    "\n",
    "class fuxi_FGCNN(BaseModel):\n",
    "    def __init__(self, \n",
    "                 feature_map, \n",
    "                 model_id=\"FGCNN\", \n",
    "                 gpu=-1, \n",
    "                 task=\"binary_classification\", \n",
    "                 learning_rate=1e-3, \n",
    "                 embedding_dim=10, \n",
    "                 share_embedding=False,\n",
    "                 channels=[14, 16, 18, 20],\n",
    "                 kernel_heights=[7, 7, 7, 7],\n",
    "                 pooling_sizes=[2, 2, 2, 2],\n",
    "                 recombined_channels=[2, 2, 2, 2],\n",
    "                 conv_activation=\"Tanh\",\n",
    "                 conv_batch_norm=True,\n",
    "                 dnn_hidden_units=[128, 64],\n",
    "                 dnn_activations=\"ReLU\",\n",
    "                 dnn_batch_norm=False, \n",
    "                 embedding_regularizer=None, \n",
    "                 net_regularizer=None,\n",
    "                 net_dropout=0,\n",
    "                 **kwargs):\n",
    "        super(fuxi_FGCNN, self).__init__(feature_map, \n",
    "                                    model_id=model_id, \n",
    "                                    gpu=gpu, \n",
    "                                    embedding_regularizer=embedding_regularizer, \n",
    "                                    net_regularizer=net_regularizer,\n",
    "                                    **kwargs)\n",
    "        self.share_embedding = share_embedding\n",
    "        self.embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        if not self.share_embedding:\n",
    "            self.fg_embedding_layer = EmbeddingLayer(feature_map, embedding_dim)\n",
    "        num_fields = feature_map.num_fields\n",
    "        channels, kernel_heights, pooling_sizes, recombined_channels \\\n",
    "            = self.validate_input(channels, \n",
    "                                  kernel_heights, \n",
    "                                  pooling_sizes, \n",
    "                                  recombined_channels)\n",
    "        self.fgcnn_layer = FGCNN_Layer(num_fields, \n",
    "                                       embedding_dim,\n",
    "                                       channels=channels, \n",
    "                                       kernel_heights=kernel_heights, \n",
    "                                       pooling_sizes=pooling_sizes,\n",
    "                                       recombined_channels=recombined_channels,\n",
    "                                       activation=conv_activation,\n",
    "                                       batch_norm=conv_batch_norm)\n",
    "        input_dim, total_features = self.compute_input_dim(embedding_dim, \n",
    "                                                           num_fields, \n",
    "                                                           channels, \n",
    "                                                           pooling_sizes, \n",
    "                                                           recombined_channels)\n",
    "        self.inner_product_layer = InnerProductLayer(total_features)#, output=\"inner_product\")\n",
    "        self.dnn = MLP_Layer(input_dim=input_dim,\n",
    "                             output_dim=1, \n",
    "                             hidden_units=dnn_hidden_units,\n",
    "                             hidden_activations=dnn_activations,\n",
    "                             final_activation=nn.Sigmoid(),\n",
    "                             dropout_rates=net_dropout,\n",
    "                             batch_norm=dnn_batch_norm)\n",
    "\n",
    "    def compute_input_dim(self, \n",
    "                          embedding_dim, \n",
    "                          num_fields, \n",
    "                          channels, \n",
    "                          pooling_sizes, \n",
    "                          recombined_channels):\n",
    "        total_features = num_fields\n",
    "        input_height = num_fields\n",
    "        for i in range(len(channels)):\n",
    "            input_height = int(np.ceil(input_height / pooling_sizes[i]))\n",
    "            total_features += input_height * recombined_channels[i]\n",
    "        input_dim = int(total_features * (total_features - 1) / 2) \\\n",
    "                  + total_features * embedding_dim\n",
    "        return input_dim, total_features\n",
    "\n",
    "    def validate_input(self, \n",
    "                       channels, \n",
    "                       kernel_heights, \n",
    "                       pooling_sizes, \n",
    "                       recombined_channels):\n",
    "        if not isinstance(kernel_heights, list):\n",
    "            kernel_heights = [kernel_heights] * len(channels)\n",
    "        if not isinstance(pooling_sizes, list):\n",
    "            pooling_sizes = [pooling_sizes] * len(channels)\n",
    "        if not isinstance(recombined_channels, list):\n",
    "            recombined_channels = [recombined_channels] * len(channels)\n",
    "        if not (len(channels) == len(kernel_heights) == len(pooling_sizes) == len(recombined_channels)):\n",
    "            raise ValueError(\"channels, kernel_heights, pooling_sizes, and recombined_channels \\\n",
    "                              should have the same length.\")\n",
    "        return channels, kernel_heights, pooling_sizes, recombined_channels\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Inputs: [X, y]\n",
    "        \"\"\"\n",
    "        X, y = self.inputs_to_device(inputs)\n",
    "        feature_emb = self.embedding_layer(X)\n",
    "        if not self.share_embedding:\n",
    "            feature_emb2 = self.fg_embedding_layer(X)\n",
    "        else:\n",
    "            feature_emb2 = feature_emb\n",
    "        conv_in = torch.unsqueeze(feature_emb2, 1)\n",
    "        new_feature_emb = self.fgcnn_layer(conv_in)\n",
    "        combined_feature_emb = torch.cat([feature_emb, new_feature_emb], dim=1)\n",
    "        inner_product_vec = self.inner_product_layer(combined_feature_emb)\n",
    "        dense_input = torch.cat([combined_feature_emb.flatten(start_dim=1), inner_product_vec], dim=1)\n",
    "        y_pred = self.dnn(dense_input)\n",
    "        return y_pred\n",
    "        return_dict = {\"y_true\": y, \"y_pred\": y_pred}\n",
    "        return return_dict\n",
    "\n",
    "\n",
    "class FGCNN_Layer(nn.Module):\n",
    "    \"\"\"\n",
    "    Input X: tensor of shape (batch_size, 1, num_fields, embedding_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 num_fields, \n",
    "                 embedding_dim,\n",
    "                 channels=[3], \n",
    "                 kernel_heights=[3], \n",
    "                 pooling_sizes=[2],\n",
    "                 recombined_channels=[2],\n",
    "                 activation=\"Tanh\",\n",
    "                 batch_norm=False):\n",
    "        super(FGCNN_Layer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        conv_list = []\n",
    "        recombine_list = []\n",
    "        self.channels = [1] + channels # input channel = 1\n",
    "        input_height = num_fields\n",
    "        for i in range(1, len(self.channels)):\n",
    "            in_channel = self.channels[i - 1]\n",
    "            out_channel = self.channels[i]\n",
    "            kernel_height = kernel_heights[i - 1]\n",
    "            pooling_size = pooling_sizes[i - 1]\n",
    "            recombined_channel = recombined_channels[i - 1]\n",
    "            conv_list.append(nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, \n",
    "                        kernel_size=(kernel_height, 1), \n",
    "                        padding=(int((kernel_height - 1) / 2), 0)),\n",
    "                nn.BatchNorm2d(out_channel),\n",
    "                nn.Tanh(),\n",
    "                nn.MaxPool2d((pooling_size, 1), stride=(pooling_size, 1), padding=(input_height % pooling_size, 0))\n",
    "            ))\n",
    "            input_height = int(np.ceil(input_height / pooling_size))\n",
    "            input_dim =  input_height * embedding_dim * out_channel\n",
    "            output_dim = input_height * embedding_dim * recombined_channel\n",
    "            recombine_layer = nn.Sequential(nn.Linear(input_dim, output_dim),\n",
    "                                            nn.Tanh())\n",
    "            recombine_list.append(recombine_layer)\n",
    "        self.conv_layers = nn.ModuleList(conv_list)\n",
    "        self.recombine_layers = nn.ModuleList(recombine_list)\n",
    "\n",
    "    def forward(self, X):\n",
    "        conv_out = X\n",
    "        new_feature_list = []\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            conv_out = self.conv_layers[i](conv_out)\n",
    "            flatten_out = torch.flatten(conv_out, start_dim=1)\n",
    "            recombine_out = self.recombine_layers[i](flatten_out)\n",
    "            new_feature_list.append(recombine_out.reshape(X.size(0), -1, self.embedding_dim))\n",
    "        new_feature_emb = torch.cat(new_feature_list, dim=1)\n",
    "        return new_feature_emb\n",
    "\n",
    "class MLP_Layer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 output_dim=None, \n",
    "                 hidden_units=[], \n",
    "                 hidden_activations=\"ReLU\",\n",
    "                 final_activation=None, \n",
    "                 dropout_rates=[], \n",
    "                 batch_norm=False, \n",
    "                 use_bias=True):\n",
    "        super(MLP_Layer, self).__init__()\n",
    "        dense_layers = []\n",
    "        if not isinstance(dropout_rates, list):\n",
    "            dropout_rates = [dropout_rates] * len(hidden_units)\n",
    "        if not isinstance(hidden_activations, list):\n",
    "            hidden_activations = [hidden_activations] * len(hidden_units)\n",
    "        hidden_activations = [set_activation(x) for x in hidden_activations]\n",
    "        hidden_units = [input_dim] + hidden_units\n",
    "        for idx in range(len(hidden_units) - 1):\n",
    "            dense_layers.append(nn.Linear(hidden_units[idx], hidden_units[idx + 1], bias=use_bias))\n",
    "            if batch_norm:\n",
    "                dense_layers.append(nn.BatchNorm1d(hidden_units[idx + 1]))\n",
    "            if hidden_activations[idx]:\n",
    "                dense_layers.append(hidden_activations[idx])\n",
    "            if dropout_rates[idx] > 0:\n",
    "                dense_layers.append(nn.Dropout(p=dropout_rates[idx]))\n",
    "        if output_dim is not None:\n",
    "            dense_layers.append(nn.Linear(hidden_units[-1], output_dim, bias=use_bias))\n",
    "        if final_activation is not None:\n",
    "            dense_layers.append(set_activation(final_activation))\n",
    "        self.dnn = nn.Sequential(*dense_layers) # * used to unpack list\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.dnn(inputs)\n",
    "\n",
    "class InnerProductLayer(nn.Module):\n",
    "    def __init__(self, num_fields=None):\n",
    "        super(InnerProductLayer, self).__init__()\n",
    "        self.interaction_units = int(num_fields * (num_fields - 1) / 2)\n",
    "        self.upper_triange_mask = torch.triu(torch.ones(num_fields, num_fields), 1).type(torch.BoolTensor)\n",
    "\n",
    "    def forward(self, feature_emb):\n",
    "        inner_product_matrix = torch.bmm(feature_emb, feature_emb.transpose(1, 2))\n",
    "        flat_upper_triange = torch.masked_select(inner_product_matrix, self.upper_triange_mask)\n",
    "        return flat_upper_triange.view(-1, self.interaction_units)\n",
    "\n",
    "torch_model = fuxi_FGCNN(feature_map, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hy-tmp/Paddle-fgcnn-version1/fgcnn/fuxi_pipline\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline\n",
    "import torch\n",
    "import pickle\n",
    "import paddle\n",
    "# from paddle_net import FGCNN as paddle_FGCNN\n",
    "from reprod_log import ReprodLogger, ReprodDiffHelper\n",
    "# path\n",
    "%cd /hy-tmp/Paddle-fgcnn-version1/fgcnn/fuxi_pipline\n",
    "# data\n",
    "pipline_data = pickle.load(open('data/sample.pkl', 'rb'))\n",
    "# torch\n",
    "torch_para = torch.load('data/torch_para.pt')\n",
    "del torch_para[\"inner_product_layer.field_p\"]\n",
    "del torch_para[\"inner_product_layer.field_q\"]\n",
    "del torch_para[\"inner_product_layer.upper_triange_mask\"]\n",
    "torch_model.load_state_dict(torch_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step1\n",
    "torch_model.eval()\n",
    "torch_forward = []\n",
    "for data in pipline_data:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # torch\n",
    "    torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "    torch_out = torch_model.forward(torch_inputs)\n",
    "    torch_forward.append(torch_out.detach().numpy())\n",
    "\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"logits\", np.array(torch_forward))\n",
    "reprod_logger.save(\"Step1/forward_torch.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2\n",
    "torch_model.eval()\n",
    "torch_cost = []\n",
    "for data in pipline_data:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # torch\n",
    "    torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "    torch_out = torch_model.forward(torch_inputs)#['y_pred']\n",
    "    torch_cost.append(torch.nn.functional.binary_cross_entropy(torch_out, torch.Tensor([label]).reshape((1,1))).detach().numpy())\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"binary_cross_entropy\", np.array(torch_cost))\n",
    "reprod_logger.save(\"Step2/metric_torch.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step4\n",
    "# torch\n",
    "torch_model.load_state_dict(torch_para)\n",
    "torch_model.eval()\n",
    "torch_optim = torch.optim.Adam(params=torch_model.parameters())\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)\n",
    "paddle_model.eval()\n",
    "paddle_optim = paddle.optimizer.Adam(parameters=paddle_model.parameters())\n",
    "# grad\n",
    "def save_paddle_hook_fn(grad):\n",
    "    global paddle_grad\n",
    "    paddle_grad.append(grad)\n",
    "\n",
    "def save_torch_hook_fn(grad):\n",
    "    global torch_grad\n",
    "    torch_grad.append(grad)\n",
    "t_out = []\n",
    "torch_loss = []\n",
    "labels = []\n",
    "torch_grad= []\n",
    "for data in pipline_data[:2]:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # torch\n",
    "    torch_optim.zero_grad()\n",
    "    torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "    torch_out = torch_model.forward(torch_inputs)#['y_pred']\n",
    "    t_loss = torch.nn.functional.binary_cross_entropy(torch_out, torch.Tensor([label]).reshape((1,1)))\n",
    "    # t_loss.register_hook(lambda grad: print('t:', grad.detach().numpy()))\n",
    "    t_loss.backward()\n",
    "    # for name, tensor in torch_model.named_parameters():\n",
    "    #     grad = tensor.grad.numpy()\n",
    "    #     torch_grad.append((name, grad))\n",
    "    torch_optim.step()\n",
    "    # test\n",
    "    t_out.append(torch_out.detach().numpy())\n",
    "    torch_loss.append(t_loss.detach().numpy())\n",
    "    labels.append(label)\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"loss\", np.array(torch_loss))\n",
    "reprod_logger.save(\"Step4/bp_align_torch.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5\n",
    "# torch\n",
    "torch_model.load_state_dict(torch_para)\n",
    "torch_model.eval()\n",
    "torch_optim = torch.optim.Adam(\n",
    "            params=torch_model.parameters(),\n",
    "            lr=0.001)\n",
    "\n",
    "t_out = []\n",
    "torch_loss = []\n",
    "for epoch in range(2):\n",
    "    for data in pipline_data:\n",
    "        data, label = data[:-1], data[-1]\n",
    "        torch_optim.zero_grad()\n",
    "        torch_inputs = list(map(torch.tensor, [data.reshape((1,-1)), label]))\n",
    "        torch_out = torch_model.forward(torch_inputs)#['y_pred']\n",
    "        t_loss = torch.nn.functional.binary_cross_entropy(torch_out, torch.Tensor([label]).reshape((1,1)))\n",
    "        # t_loss.register_hook(lambda grad: print('t:', grad.detach().numpy()))\n",
    "        t_loss.backward()\n",
    "        torch_optim.step()\n",
    "        # test\n",
    "        t_out.append(torch_out.detach().numpy())\n",
    "        torch_loss.append(t_loss.detach().numpy())\n",
    "    # print(torch_loss)\n",
    "    # print(paddle_loss)\n",
    "# torch\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"train\", np.array(torch_loss))\n",
    "reprod_logger.save(\"Step5/train_torch1.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## paddle-FGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "import numpy as np\n",
    "from paddle.nn import functional as F\n",
    "\n",
    "\n",
    "class paddle_FGCNN(nn.Layer):\n",
    "    def __init__(self, sparse_num_field, sparse_feature_size,\n",
    "                 sparse_feature_name, sparse_feature_dim, conv_kernel_width,\n",
    "                 conv_filters, new_maps, pooling_width,\n",
    "                 dnn_hidden_units, dnn_dropout):\n",
    "        '''\n",
    "        Parameters\n",
    "            sparse_num_field - \n",
    "            sparse_feature_size - \n",
    "            sparse_feature_name - \n",
    "            sparse_feature_dim - \n",
    "            conv_kernel_width - \n",
    "            conv_filters - \n",
    "            new_maps - \n",
    "            pooling_width - \n",
    "            dnn_hidden_units - \n",
    "            dnn_dropout - \n",
    "        '''\n",
    "        super(paddle_FGCNN, self).__init__()\n",
    "        self.sparse_num_field = sparse_num_field\n",
    "        self.sparse_feature_size = sparse_feature_size\n",
    "        self.sparse_feature_name = sparse_feature_name\n",
    "        self.sparse_feature_dim = sparse_feature_dim\n",
    "        self.conv_filters = conv_filters\n",
    "        self.conv_kernel_width = conv_kernel_width\n",
    "        self.new_maps = new_maps\n",
    "        self.pooling_width = pooling_width\n",
    " \n",
    "        \n",
    "        self.fg_embedding = nn.LayerList([\n",
    "            EmbeddingLayer(\n",
    "                num_embeddings=self.sparse_feature_size[i],\n",
    "                embedding_dim=self.sparse_feature_dim,\n",
    "                feature_name=self.sparse_feature_name[i] + '_fg_emd'\n",
    "            ) for i in range(self.sparse_num_field)])\n",
    "\n",
    "        self.embedding = nn.LayerList([\n",
    "            EmbeddingLayer(\n",
    "                num_embeddings=self.sparse_feature_size[i],\n",
    "                embedding_dim=self.sparse_feature_dim,\n",
    "                feature_name=self.sparse_feature_name[i] + '_emd'\n",
    "            ) for i in range(self.sparse_num_field)])\n",
    "\n",
    "        self.fgcnn = FGCNNLayer(self.sparse_num_field, self.sparse_feature_dim,\n",
    "                                self.conv_filters, self.conv_kernel_width, \n",
    "                                self.new_maps, self.pooling_width)\n",
    "        input_dim, total_features = self.compute_input_dim(\n",
    "            self.sparse_feature_dim,\n",
    "            self.sparse_num_field,\n",
    "            self.conv_filters,\n",
    "            self.pooling_width, \n",
    "            self.new_maps)\n",
    "        self.inner_product_layer = InnerProductLayer(total_features)\n",
    "        self.dnn = DNNLayer(input_dim, dnn_hidden_units, dnn_dropout)\n",
    "\n",
    "    def compute_input_dim(self, embedding_dim, num_fields, channels, \n",
    "                          pooling_sizes, recombined_channels):\n",
    "        total_features = num_fields\n",
    "        input_height = num_fields\n",
    "        for i in range(len(channels)):\n",
    "            input_height = int(np.ceil(input_height / pooling_sizes[i]))\n",
    "            total_features += input_height * recombined_channels[i]\n",
    "        input_dim = int(total_features * (total_features - 1) / 2) \\\n",
    "                  + total_features * embedding_dim\n",
    "        return input_dim, total_features\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = paddle.to_tensor(inputs).reshape((-1, self.sparse_num_field))\n",
    "        fg_input_list = []\n",
    "        origin_input_list = []\n",
    "        for i in range(self.sparse_num_field):\n",
    "            fg_input_list.append(\n",
    "                self.fg_embedding[i](inputs[:, i].astype('int64'))\n",
    "                .reshape((-1, 1, self.sparse_feature_dim)))\n",
    "            origin_input_list.append(\n",
    "                self.embedding[i](inputs[:, i].astype('int64'))\n",
    "                .reshape((-1, 1, self.sparse_feature_dim)))\n",
    "        fg_input = paddle.concat(fg_input_list, axis=1)\n",
    "        origin_input = paddle.concat(origin_input_list, axis=1)\n",
    "        new_features = self.fgcnn(fg_input)\n",
    "        combined_input = paddle.concat([origin_input, new_features], axis=1)\n",
    "        linear_signal = paddle.flatten(combined_input, start_axis=1)\n",
    "        inner_product_vec = self.inner_product_layer(combined_input)\n",
    "        # print('linear_signal:', linear_signal.shape)\n",
    "        # print('inner_prodcut', inner_product.shape)\n",
    "        dnn_input = paddle.concat([linear_signal, inner_product_vec], axis=1)\n",
    "        # dnn_input = linear_signal\n",
    "        # return dnn_input\n",
    "        # print('dnn_input:', dnn_input.shape)\n",
    "        y_pred = self.dnn(dnn_input)\n",
    "        return y_pred\n",
    "\n",
    "class EmbeddingLayer(nn.Layer):\n",
    "    def __init__(self, num_embeddings, embedding_dim, feature_name):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embeddings=num_embeddings,\n",
    "            embedding_dim=embedding_dim,\n",
    "            name=feature_name,\n",
    "            sparse=True\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.embedding(inputs)\n",
    "    \n",
    "class FGCNNLayer(nn.Layer):\n",
    "    def __init__(self, sparse_num_field, embedding_size, filters, kernel_width, new_maps, pooling_width):\n",
    "        super(FGCNNLayer, self).__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        conv_list = []\n",
    "        recombine_list = []\n",
    "        self.filters = [1] + filters # input channel = 1\n",
    "        input_height = sparse_num_field\n",
    "        for i in range(1, len(self.filters)):\n",
    "            in_channel = self.filters[i - 1]\n",
    "            out_channel = self.filters[i]\n",
    "            kernel_height = kernel_width[i - 1]\n",
    "            pooling_size = pooling_width[i - 1]\n",
    "            recombined_channel = new_maps[i - 1]\n",
    "            conv_layer = nn.Sequential(\n",
    "                nn.Conv2D(\n",
    "                    in_channels=in_channel, \n",
    "                    out_channels=out_channel, \n",
    "                    kernel_size=(kernel_height, 1), \n",
    "                    padding=(int((kernel_height - 1) / 2), 0)),\n",
    "                nn.BatchNorm2D(out_channel),\n",
    "                nn.Tanh(),\n",
    "                nn.MaxPool2D(\n",
    "                    kernel_size=(pooling_size, 1), \n",
    "                    stride=(pooling_size, 1),\n",
    "                    padding=(input_height % pooling_size, 0)))\n",
    "            # )\n",
    "            conv_list.append(conv_layer)\n",
    "\n",
    "            input_height = int(np.ceil(input_height / pooling_size))\n",
    "            input_dim =  input_height * embedding_size * out_channel\n",
    "            output_dim = input_height * embedding_size * recombined_channel\n",
    "            # print('in: %d, out:%d' % (input_dim, output_dim))\n",
    "            recombine_layer = nn.Sequential(\n",
    "                nn.Linear(\n",
    "                    in_features=input_dim, \n",
    "                    out_features=output_dim), \n",
    "                nn.Tanh())\n",
    "            recombine_list.append(recombine_layer)\n",
    "\n",
    "        self.conv_layers = nn.LayerList(conv_list)\n",
    "        self.recombine_layers = nn.LayerList(recombine_list)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        conv_out = inputs.unsqueeze(1)\n",
    "        new_feature_list = []\n",
    "        for i in range(len(self.filters) - 1):\n",
    "            conv_out = self.conv_layers[i](conv_out)\n",
    "            flatten_out = paddle.flatten(conv_out, start_axis=1)\n",
    "            # return flatten_out\n",
    "            recombine_out = self.recombine_layers[i](flatten_out)\n",
    "            # print(flatten_out.shape)\n",
    "            # return recombine_out\n",
    "            recombine_out = recombine_out.reshape((inputs.shape[0], -1, self.embedding_size))\n",
    "            new_feature_list.append(recombine_out)\n",
    "        # return new_feature_list\n",
    "        new_features = paddle.concat(new_feature_list, axis=1)\n",
    "        return new_features\n",
    "\n",
    "class InnerProductLayer(nn.Layer):\n",
    "    \"\"\" output: product_sum_pooling (bs x 1), \n",
    "                Bi_interaction_pooling (bs * dim), \n",
    "                inner_product (bs x f2/2), \n",
    "                elementwise_product (bs x f2/2 x emb_dim)\n",
    "    \"\"\"\n",
    "    def __init__(self, num_fields=None):\n",
    "        super(InnerProductLayer, self).__init__()\n",
    "        if num_fields is None:\n",
    "            raise ValueError(\"num_fields is required\")\n",
    "        else:\n",
    "            self.num_fields = num_fields\n",
    "            self.interaction_units = int(num_fields * (num_fields - 1) / 2)\n",
    "            \n",
    "    def forward(self, feature_emb):\n",
    "        onemask = paddle.ones(shape=[feature_emb.shape[0],self.num_fields, self.num_fields],dtype='int32')\n",
    "        tri = paddle.triu(onemask,1)\n",
    "        upper_triange_mask = paddle.cast(tri,'bool')\n",
    "        inner_product_matrix = paddle.bmm(feature_emb, paddle.transpose(feature_emb, perm=[0, 2, 1]))\n",
    "        flat_upper_triange = paddle.masked_select(inner_product_matrix, upper_triange_mask)\n",
    "        return flat_upper_triange.reshape([-1, self.interaction_units])\n",
    "\n",
    "\n",
    "class DNNLayer(nn.Layer):\n",
    "    def __init__(self, inputs_dim, hidden_units, dropout_rate):\n",
    "        super(DNNLayer, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        hidden_units = [inputs_dim] + list(hidden_units)\n",
    "        layers = []\n",
    "        for i in range(len(hidden_units) - 1):\n",
    "            layers.append(nn.Linear(\n",
    "                in_features=hidden_units[i], \n",
    "                out_features=hidden_units[i + 1],\n",
    "                name='dnn_%d' % i))\n",
    "            layers.append(nn.ReLU())\n",
    "            if self.dropout_rate > 0:\n",
    "                layers.append(self.dropout)\n",
    "        layers.append(nn.Linear(\n",
    "            in_features=hidden_units[-1],\n",
    "            out_features=1,\n",
    "            name='dnn_%d' % (i+1)))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.dnn = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        return self.dnn(inputs)\n",
    "\n",
    "# hyperparameters\n",
    "sparse_num_field = 14\n",
    "sparse_feature_size = [25, 95, 3, 48, 98, 97, 66, 10, 10, 3, 6, 3, 4, 3]\n",
    "sparse_feature_name = ['userid', 'adgroup_id', 'pid', 'cate_id', 'campaign_id', 'customer', 'brand', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level', 'pvalue_level', 'shopping_level', 'occupation']\n",
    "sparse_feature_dim = 10\n",
    "conv_kernel_width =  [7, 7, 7, 7]\n",
    "conv_filters =  [14, 16, 18, 20]\n",
    "new_maps =  [3, 3, 3, 3]\n",
    "pooling_width =  [2, 2, 2, 2]\n",
    "dnn_hidden_units =  [128, 64]\n",
    "dnn_dropout =  0.0\n",
    "paddle_model = paddle_FGCNN(sparse_num_field, sparse_feature_size,\n",
    "                 sparse_feature_name, sparse_feature_dim, conv_kernel_width,\n",
    "                 conv_filters, new_maps, pooling_width,\n",
    "                 dnn_hidden_units, dnn_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "import torch\n",
    "import pickle\n",
    "import paddle\n",
    "# from paddle_net import FGCNN as paddle_FGCNN\n",
    "from reprod_log import ReprodLogger, ReprodDiffHelper\n",
    "# data\n",
    "pipline_data = pickle.load(open('data/sample.pkl', 'rb'))\n",
    "# torch\n",
    "torch_para = torch.load('data/torch_para.pt')\n",
    "del torch_para[\"inner_product_layer.field_p\"]\n",
    "del torch_para[\"inner_product_layer.field_q\"]\n",
    "del torch_para[\"inner_product_layer.upper_triange_mask\"]\n",
    "# name map\n",
    "name_map = {k:v for k,v in enumerate(sparse_feature_name)}\n",
    "# fuxi\n",
    "torch_linear_key = \\\n",
    "    ['dnn.dnn.%d.weight' % i for i in [0, 2, 4]] + \\\n",
    "    ['dnn.dnn.%d.bias' % i for i in [0, 2, 4]] + \\\n",
    "    ['fgcnn_layer.recombine_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.recombine_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.running_mean' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.running_var' % i for i in range(4)] \n",
    "torch_other_key = \\\n",
    "    ['embedding_layer.embedding_layer.embedding_layer.%s.weight' % v for v in name_map.values()] + \\\n",
    "    ['fg_embedding_layer.embedding_layer.embedding_layer.%s.weight' % v for v in name_map.values()] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn_layer.conv_layers.%d.1.bias' % i for i in range(4)]\n",
    "# torch_inner_key = 'inner_product_layer.upper_triange_mask'\n",
    "# paddle\n",
    "paddle_linear_key = \\\n",
    "    ['dnn.dnn.%d.weight' % i for i in [0, 2, 4]] + \\\n",
    "    ['dnn.dnn.%d.bias' % i for i in [0, 2, 4]] + \\\n",
    "    ['fgcnn.recombine_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.recombine_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1._mean' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1._variance' % i for i in range(4)]\n",
    "paddle_other_key = \\\n",
    "    ['embedding.%d.embedding.weight' % k for k in name_map.keys()] + \\\n",
    "    ['fg_embedding.%d.embedding.weight' % k for k in name_map.keys()] + \\\n",
    "    ['fgcnn.conv_layers.%d.0.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1.weight' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.0.bias' % i for i in range(4)] + \\\n",
    "    ['fgcnn.conv_layers.%d.1.bias' % i for i in range(4)]\n",
    "# paddle_inner_key = 'inner_product_layer.upper_triange_mask'\n",
    "# fuxi2paddle\n",
    "key_map = {key_t:key_p for key_t, key_p in zip(torch_other_key, paddle_other_key)}\n",
    "paddle_para = {key_map[k]:paddle.to_tensor(v.numpy()) for k, v in torch_para.items() if k in torch_other_key}\n",
    "for t, p in zip(torch_linear_key, paddle_linear_key):\n",
    "    if t in torch_para.keys():\n",
    "        paddle_para[p] = paddle.to_tensor(torch_para[t].T.numpy())\n",
    "paddle_model.load_dict(paddle_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1\n",
    "paddle_model.eval()\n",
    "paddle_forward = []\n",
    "for data in pipline_data:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    paddle_out = paddle_model.forward(data)\n",
    "    paddle_forward.append(paddle_out.numpy())\n",
    "\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"logits\", np.array(paddle_forward))\n",
    "reprod_logger.save(\"Step1/forward_paddle.npy\")\n",
    "# diff\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"Step1/forward_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"Step1/forward_paddle.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"Diff/forward_diff.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step2\n",
    "paddle_model.eval()\n",
    "paddle_cost = []\n",
    "for data in pipline_data:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # paddle\n",
    "    paddle_out = paddle_model.forward(data)\n",
    "    paddle_cost.append(paddle.nn.functional.binary_cross_entropy(paddle_out, paddle.to_tensor(float(label)).reshape((1,1))).numpy()[0])\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"binary_cross_entropy\", np.array(paddle_cost))\n",
    "reprod_logger.save(\"Step2/metric_paddle.npy\")\n",
    "# diff\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"Step2/metric_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"Step2/metric_paddle.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"Diff/metric_diff.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)\n",
    "paddle_model.eval()\n",
    "paddle_optim = paddle.optimizer.Adam(parameters=paddle_model.parameters())\n",
    "# grad\n",
    "def save_paddle_hook_fn(grad):\n",
    "    global paddle_grad\n",
    "    paddle_grad.append(grad)\n",
    "\n",
    "p_out = []\n",
    "paddle_loss = []\n",
    "labels = []\n",
    "paddle_grad = []\n",
    "for data in pipline_data[:2]:\n",
    "    data, label = data[:-1], data[-1]\n",
    "    # paddle\n",
    "    paddle_optim.clear_grad()\n",
    "    paddle_out = paddle_model.forward(data)\n",
    "    print(paddle_out)\n",
    "    p_loss = paddle.nn.functional.binary_cross_entropy(paddle_out, paddle.to_tensor(float(label)).reshape((1,1)))\n",
    "    p_loss.backward()\n",
    "    paddle_optim.step()\n",
    "    # test\n",
    "    p_out.append(paddle_out.numpy())\n",
    "    paddle_loss.append(p_loss.numpy())\n",
    "    labels.append(label)\n",
    "\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"loss\", np.array(paddle_loss).reshape(-1))\n",
    "reprod_logger.save(\"Step4/bp_align_paddle.npy\")\n",
    "# diff\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"Step4/bp_align_torch.npy\")\n",
    "paddle_info = diff_helper.load_info(\"Step4/bp_align_paddle.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"Diff/bp_align_diff.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5\n",
    "# paddle\n",
    "paddle_model.load_dict(paddle_para)\n",
    "paddle_model.eval()\n",
    "paddle_optim = paddle.optimizer.Adam(\n",
    "            parameters=paddle_model.parameters(),\n",
    "            learning_rate=0.001)\n",
    "p_out = []\n",
    "paddle_loss = []\n",
    "for epoch in range(2):\n",
    "    for data in pipline_data:\n",
    "        data, label = data[:-1], data[-1]\n",
    "        # paddle\n",
    "        paddle_optim.clear_grad()\n",
    "        paddle_out = paddle_model.forward(data)\n",
    "        p_loss = paddle.nn.functional.binary_cross_entropy(paddle_out, paddle.to_tensor(float(label)).reshape((1,1)))\n",
    "        p_loss.backward()\n",
    "        paddle_optim.step()\n",
    "        # test\n",
    "        p_out.append(paddle_out.numpy())\n",
    "        paddle_loss.append(p_loss.numpy())\n",
    "    # print(torch_loss)\n",
    "    # print(paddle_loss)\n",
    "# paddle\n",
    "reprod_logger = ReprodLogger()\n",
    "reprod_logger.add(\"train\", np.array(paddle_loss))\n",
    "reprod_logger.save(\"Step5/train_paddle1.npy\")\n",
    "# step 5\n",
    "diff_helper = ReprodDiffHelper()\n",
    "torch_info = diff_helper.load_info(\"Step5/train_torch1.npy\")\n",
    "paddle_info = diff_helper.load_info(\"Step5/train_paddle1.npy\")\n",
    "\n",
    "diff_helper.compare_info(torch_info, paddle_info)\n",
    "\n",
    "diff_helper.report(path=\"Diff/loss_diff.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "label = np.array([0, 0, 1, 1])\n",
    "pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "# torch\n",
    "print(roc_auc_score(label, pred))\n",
    "# paddle\n",
    "m = paddle.metric.Auc()\n",
    "\n",
    "class1_preds = pred.reshape(-1, 1)\n",
    "class0_preds = 1 - class1_preds\n",
    "\n",
    "preds = np.concatenate((class0_preds, class1_preds), axis=1)\n",
    "\n",
    "m.update(preds=preds, labels=label)\n",
    "print(m.accumulate())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "762831eace365ee16f120c22ed7d5689be70c5a8e9076c823f0ed1712f1c33fd"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
